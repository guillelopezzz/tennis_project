{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a meter el nivel de torneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ranking_scores import puntos_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_head_to_head(dataset):\n",
    "    # Convertir la columna 'tourney_date' a formato de fecha\n",
    "    dataset['tourney_date'] = pd.to_datetime(dataset['tourney_date'], format='%Y%m%d')\n",
    "\n",
    "    # Ordenar el dataset por fecha\n",
    "    dataset = dataset.sort_values('tourney_date')\n",
    "\n",
    "    # Inicializar una nueva columna para el historial de enfrentamientos directos\n",
    "    dataset['head_to_head'] = 0.5\n",
    "    '''dataset['num_matches'] = 0'''\n",
    "    # Iterar sobre las filas del dataset\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Obtener los partidos anteriores entre los dos jugadores\n",
    "        previous_matches = dataset[((dataset['winner_id'] == row['winner_id']) & (dataset['loser_id'] == row['loser_id']) | (dataset['winner_id'] == row['loser_id']) & (dataset['loser_id'] == row['winner_id'])) & (dataset['tourney_date'] < row['tourney_date'])]\n",
    "\n",
    "        if not previous_matches.empty:\n",
    "            # Calcular el porcentaje de veces que el 'winner_id' ha ganado\n",
    "            wins = len(previous_matches[previous_matches['winner_id'] == row['winner_id']])\n",
    "            total = len(previous_matches)\n",
    "            dataset.at[index, 'head_to_head'] = wins / total\n",
    "            '''# Calcular el número de partidos jugados\n",
    "            dataset.at[index, 'num_matches'] = total'''\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de los años\n",
    "data_2021 = pd.read_csv('atp_matches_2021.csv')\n",
    "data_2022 = pd.read_csv('atp_matches_2022.csv')\n",
    "data_2023 = pd.read_csv('atp_matches_2023.csv')\n",
    "\n",
    "# Agregar una columna 'source' a cada DataFrame\n",
    "data_2021['source'] = 'atp_matches_2021.csv'\n",
    "data_2022['source'] = 'atp_matches_2022.csv'\n",
    "data_2023['source'] = 'atp_matches_2023.csv'\n",
    "\n",
    "# Combinar los datos en un solo DataFrame\n",
    "data_all = pd.concat([data_2021, data_2022, data_2023])\n",
    "\n",
    "# Aplicar la función calculate_head_to_head\n",
    "data_all = calculate_head_to_head(data_all)\n",
    "\n",
    "# Filtrar los datos para obtener solo los partidos de 2023 del archivo 'atp_matches_2023.csv'\n",
    "dataset = data_all[data_all['source'] == 'atp_matches_2023.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenistas = pd.concat([dataset['winner_id'], dataset['loser_id']])\n",
    "tenistas = set(tenistas)\n",
    "num_tenistas = len(tenistas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_r = pd.read_csv('atp_rankings_20s.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos el tratamiento de los NaN's antes de nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos el valor más común entre 'Grass', 'Hard', y 'Clay'\n",
    "most_common = dataset[dataset['surface'].isin(['Grass', 'Hard', 'Clay'])]['surface'].mode()[0]\n",
    "\n",
    "# Reemplazamos los valores que no son 'Grass', 'Hard', o 'Clay' (los NaN's) con el valor más común\n",
    "dataset.loc[~dataset['surface'].isin(['Grass', 'Hard', 'Clay']), 'surface'] = most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guille\\OneDrive\\Escritorio\\Deepty Projects\\ranking_scores.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['tourney_date'] = pd.to_datetime(dataset['tourney_date'], format='%Y%m%d')\n",
      "c:\\Users\\Guille\\OneDrive\\Escritorio\\Deepty Projects\\ranking_scores.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['year_month'] = dataset['tourney_date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "pk = puntos_ranking(dataset, dataset_r, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:, 'winner_rank_points'], dataset.loc[:, 'loser_rank_points'] = pk['winner_points'], pk['loser_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>...</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "      <th>winner_rank</th>\n",
       "      <th>winner_rank_points</th>\n",
       "      <th>loser_rank</th>\n",
       "      <th>loser_rank_points</th>\n",
       "      <th>source</th>\n",
       "      <th>head_to_head</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2023-2843</td>\n",
       "      <td>Adelaide 1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>279</td>\n",
       "      <td>207733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>atp_matches_2023.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2023-2843</td>\n",
       "      <td>Adelaide 1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>278</td>\n",
       "      <td>111575</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>atp_matches_2023.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-2843</td>\n",
       "      <td>Adelaide 1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>277</td>\n",
       "      <td>206173</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>atp_matches_2023.csv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2023-2843</td>\n",
       "      <td>Adelaide 1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>276</td>\n",
       "      <td>106423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WC</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>atp_matches_2023.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2023-2843</td>\n",
       "      <td>Adelaide 1</td>\n",
       "      <td>Hard</td>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>272</td>\n",
       "      <td>111456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>atp_matches_2023.csv</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tourney_id tourney_name surface  draw_size tourney_level tourney_date  \\\n",
       "69  2023-2843   Adelaide 1    Hard         32             A   2023-01-02   \n",
       "70  2023-2843   Adelaide 1    Hard         32             A   2023-01-02   \n",
       "71  2023-2843   Adelaide 1    Hard         32             A   2023-01-02   \n",
       "72  2023-2843   Adelaide 1    Hard         32             A   2023-01-02   \n",
       "76  2023-2843   Adelaide 1    Hard         32             A   2023-01-02   \n",
       "\n",
       "    match_num  winner_id  winner_seed winner_entry  ... l_SvGms l_bpSaved  \\\n",
       "69        279     207733          NaN          NaN  ...     8.0       7.0   \n",
       "70        278     111575          8.0          NaN  ...     9.0       8.0   \n",
       "71        277     206173          6.0          NaN  ...     8.0       1.0   \n",
       "72        276     106423          NaN           WC  ...    12.0       5.0   \n",
       "76        272     111456          NaN          NaN  ...     5.0       0.0   \n",
       "\n",
       "    l_bpFaced winner_rank  winner_rank_points  loser_rank  loser_rank_points  \\\n",
       "69       12.0        42.0               990.0        83.0              630.0   \n",
       "70       12.0        20.0              1990.0        57.0              813.0   \n",
       "71        4.0        15.0              2410.0       582.0               52.0   \n",
       "72        6.0        93.0               592.0        34.0             1163.0   \n",
       "76        2.0        63.0               775.0        67.0              741.0   \n",
       "\n",
       "                  source head_to_head year_month  \n",
       "69  atp_matches_2023.csv          0.5    2023-01  \n",
       "70  atp_matches_2023.csv          0.5    2023-01  \n",
       "71  atp_matches_2023.csv          1.0    2023-01  \n",
       "72  atp_matches_2023.csv          0.5    2023-01  \n",
       "76  atp_matches_2023.csv          0.5    2023-01  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X = dataset.iloc[:, [7, 15, -1, -3, 2]].values\\ny = dataset.iloc[:, 7].values'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Indice 7: ganador del partido.\n",
    "Indice 15: perdedor del partido.\n",
    "Indice -1: puntos en el ranking del jugador ganador\n",
    "Indice -3: puntos en el ranking del jugador perdedor\n",
    "Indice 2: tipo de campo del partido (grass, hard o clay)'''\n",
    "'''X = dataset.iloc[:, [7, 15, -1, -3, 2]].values\n",
    "y = dataset.iloc[:, 7].values'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_X = ['winner_id', 'loser_id', 'winner_rank_points', 'loser_rank_points', 'head_to_head', 'tourney_level', 'surface']\n",
    "columna_y = 'winner_id'\n",
    "X = dataset[columnas_X].values\n",
    "y = np.zeros(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 0] = X[:, 0].astype(str)\n",
    "X[:, 1] = X[:, 1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el codificador\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Ajustar el codificador con los datos de ambos jugadores y 'y'\n",
    "encoder.fit(X[:, [0, 1]].reshape(-1, 1))\n",
    "\n",
    "# Transformar las columnas de los jugadores\n",
    "player1_onehot = encoder.transform(X[:, 0].reshape(-1, 1))\n",
    "player2_onehot = encoder.transform(X[:, 1].reshape(-1, 1))\n",
    "\n",
    "\n",
    "# Concatenar las columnas one-hot con el resto de tus datos\n",
    "X = np.concatenate([player1_onehot[:, :-1], player2_onehot[:, :-1], X[:, 2:]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de booleanos aleatorios del mismo tamaño que tus datos\n",
    "swap = np.random.rand(len(X)) > 0.5\n",
    "\n",
    "# Intercambiamos las posiciones de los jugadores en 'X' donde 'swap' es True\n",
    "X[swap, :num_tenistas-1], X[swap, num_tenistas-1:num_tenistas*2-2] = X[swap, num_tenistas-1:num_tenistas*2-2], X[swap, :num_tenistas-1].copy()\n",
    "\n",
    "# Intercambiamos las posiciones de los puntos en el ranking donde 'swap' es True\n",
    "X[swap, num_tenistas*2-2], X[swap, num_tenistas*2+1-2] = X[swap, num_tenistas*2+1-2], X[swap, num_tenistas*2-2].copy()\n",
    "\n",
    "mask = (swap) & (X[:, -3] != -1)\n",
    "X[mask, -3] = 1 - X[mask, -3]\n",
    "\n",
    "y[swap] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "# Ajustamos y transformamos las dos últimas columnas de tus datos\n",
    "X[:, [-5, -4]] = scaler.fit_transform(X[:, [-5, -4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para el tipo de campo\n",
    "# Crear el codificador\n",
    "encoder2 = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Ajustar y transformar la columna del tipo de campo\n",
    "field_type_onehot = encoder2.fit_transform(X[:, num_tenistas*2-2+4].reshape(-1, 1))\n",
    "\n",
    "# Concatenar la columna one-hot con el resto de los datos\n",
    "X = np.concatenate([X[:, :num_tenistas*2-2+4], field_type_onehot[:, :-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para el nivel del torneo\n",
    "# Crear el codificador\n",
    "encoder3 = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Ajustar y transformar la columna del tipo de campo\n",
    "tourney_level_onehot = encoder2.fit_transform(X[:, num_tenistas*2-2+3].reshape(-1, 1))\n",
    "\n",
    "# Concatenar la columna one-hot con el resto de los datos\n",
    "X = np.concatenate([X[:, :num_tenistas*2-2+3], tourney_level_onehot[:, :-1], X[:, num_tenistas*2-2+4:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento (60%) y validación (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_val = X_val.astype('float64')\n",
    "y_val = y_val.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6903 - accuracy: 0.5349 - val_loss: 0.6743 - val_accuracy: 0.6370\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6447 - val_loss: 0.6509 - val_accuracy: 0.6866\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6931 - val_loss: 0.6172 - val_accuracy: 0.6969\n",
      "19/19 [==============================] - 0s 828us/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 0.6896 - accuracy: 0.5474 - val_loss: 0.6712 - val_accuracy: 0.6353\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6464 - val_loss: 0.6463 - val_accuracy: 0.6849\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.7025 - val_loss: 0.6192 - val_accuracy: 0.6815\n",
      "19/19 [==============================] - 0s 999us/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.5465 - val_loss: 0.6736 - val_accuracy: 0.6455\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6339 - val_loss: 0.6483 - val_accuracy: 0.6866\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6910 - val_loss: 0.6131 - val_accuracy: 0.7021\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.5645 - val_loss: 0.6736 - val_accuracy: 0.6250\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6404 - val_loss: 0.6508 - val_accuracy: 0.6610\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6948 - val_loss: 0.6231 - val_accuracy: 0.6884\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.5324 - val_loss: 0.6757 - val_accuracy: 0.6267\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6314 - val_loss: 0.6553 - val_accuracy: 0.6644\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6811 - val_loss: 0.6268 - val_accuracy: 0.6832\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.5366 - val_loss: 0.6722 - val_accuracy: 0.6507\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6494 - val_loss: 0.6468 - val_accuracy: 0.6901\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7034 - val_loss: 0.6117 - val_accuracy: 0.7021\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Epoch 1/3\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.5324 - val_loss: 0.6736 - val_accuracy: 0.6370\n",
      "Epoch 2/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6339 - val_loss: 0.6518 - val_accuracy: 0.6678\n",
      "Epoch 3/3\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6807 - val_loss: 0.6186 - val_accuracy: 0.6884\n",
      "19/19 [==============================] - 0s 889us/step\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    893\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    894\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    895\u001b[0m           args, kwds))\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\optim-2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Vamos a inferir la media poblacional a partir de una muestra aleatoria simple con n = 300\n",
    "muestras = [0 for _ in range(300)]\n",
    "for i in range(300):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train = X_train.astype('float64')\n",
    "    y_train = y_train.astype('float64')\n",
    "    # Definimos el modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # Añadir la capa de entrada y la primera capa oculta\n",
    "    model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    # Añadir la segunda capa oculta\n",
    "    # model.add(Dense(units=32, activation='tanh'))\n",
    "\n",
    "    # Añadir la capa de salida\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=32)\n",
    "\n",
    "    X_test = X_test.astype('float64')\n",
    "    y_test = y_test.astype('float64')\n",
    "\n",
    "    # Hacemos la predicción\n",
    "    prediccion_test = model.predict(X_test)\n",
    "    predicciones = [1 if p > 0.5 else 0 for p in prediccion_test]\n",
    "    # Veamos cuántos partidos ha acertado para el test\n",
    "    aciertos = 0\n",
    "    for j in range(len(predicciones)):\n",
    "        if predicciones[j] == y_test[j]:\n",
    "            aciertos += 1\n",
    "    precision = aciertos / len(predicciones)*100\n",
    "    muestras[i] = precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIkCAYAAADyA9ErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABisElEQVR4nO3deVxU9f7H8feAMuyIsiuKKWnuO5lrSqKZaWUu93Y1KjW3NGyzcisNNTNzyaWuabtlZatbuFSK5lq5lXrdUsEdFBUUzu+P+TE6Agp4dCBfz8fjPJj5nu+c+Zw5wzBvzjnfYzEMwxAAAAAA4Lq4OLsAAAAAAPgnIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAF4B8pPT1dr732mhYvXuzsUoBi48svv9SECROUmZnp7FIAoFgiXAHF3MiRI2WxWG7Kc7Vs2VItW7a031+xYoUsFovmz59/U57/chaLRSNHjsxzflxcnD766CNFRUXdvKJuUdnvgxUrVhTq8Wa/h+fMmSOLxaK9e/eatsyi5lrv/9w8+uijioiIyHP+6tWr9e9//1vVqlWTq6vr9RUIALcowhVQhGR/Kcye3N3dFRYWppiYGE2ePFmnT5825XkOHTqkkSNHavPmzaYsr6j57LPPtGDBAi1cuFClSpVydjlFwttvv605c+Y4uwwUUcePH1e3bt00efJk3Xvvvc4u54Y5d+6cHn/8cdWoUUN+fn7y9vZW7dq19dZbb+nChQs5+p86dUq9e/dWYGCgvLy8dPfdd2vjxo25Lvubb75RvXr15O7urvLly2vEiBG6ePHijV4lp/nhhx8KHPCBW0EJZxcAIKdXXnlFFStW1IULF5SUlKQVK1Zo8ODBmjhxor755hvVqlXL3vfll1/WCy+8UKDlHzp0SKNGjVJERITq1KmT78ctWbKkQM9zI507d04lSuT8CDMMQ3///bcWLlyo8uXLO6Gyountt99WQECAHn30UWeXAhPk9f6/mnfeeUdZWVm5ztu0aZNGjx6tHj16mFFekXXu3Dlt3bpV9957ryIiIuTi4qLVq1fr6aef1tq1a/Xxxx/b+2ZlZal9+/b67bff9OyzzyogIEBvv/22WrZsqQ0bNigyMtLed+HCherUqZNatmypKVOm6I8//tDo0aN15MgRTZ8+3RmresP98MMPmjZtGgELuALhCiiC2rVrpwYNGtjvDx06VMuWLdN9992n+++/X9u3b5eHh4ckqUSJEgX+klVQZ8+elaenp9zc3G7o8xSEu7t7ru0Wi0VxcXE3uZp/lrS0NHl5eTm7jH+ErKwsZWRk5Pl+LazCLK9kyZJ5zouOjr6ecoqN0qVLa82aNQ5tTz75pPz8/DR16lRNnDhRISEhkqT58+dr9erV+vzzz9W5c2dJUpcuXXT77bdrxIgRDkHsmWeeUa1atbRkyRL757Gvr69ee+01DRo0SFWrVr1Ja1g0Xbx4UVlZWUXqbwhwo3BYIFBMtGrVSsOGDdO+ffv04Ycf2ttzO19l6dKlatq0qUqVKiVvb29VqVJFL774oiTb+TENGzaUJMXGxtoPQcw+ZKxly5aqUaOGNmzYoObNm8vT09P+2CvPucqWmZmpF198USEhIfLy8tL999+vAwcOOPSJiIjIda9Jbss8f/68Ro4cqdtvv13u7u4KDQ3Vgw8+qN27d9v75HbOyaZNm9SuXTv5+vrK29tbrVu3zvFFKvvQy1WrVikuLs5+uM8DDzygo0eP5qjvSo8++qi8vb21f/9+3XffffL29lbZsmU1bdo0SdIff/yhVq1aycvLSxUqVHD4AiblfX5RXucJLVy4UM2aNZOXl5d8fHzUvn17bd261aFPUlKSYmNjVa5cOVmtVoWGhqpjx472ZUVERGjr1q1auXKlfXtnv+bZz7ty5Ur169dPQUFBKleunCRp37596tevn6pUqSIPDw+VKVNGDz/88HWdy/TLL7+oYcOGcnd3V6VKlTRz5sw8+3744YeqX7++PDw8VLp0aXXr1i3H+yq/vv76a7Vv315hYWGyWq2qVKmSXn311XwN3JC9zXbs2KEuXbrI19dXZcqU0aBBg3T+/HmHvhaLRQMGDNBHH32k6tWry2q1atGiRZKkgwcP6rHHHlNwcLCsVquqV6+u2bNn53i+wrz/T58+rcGDBysiIkJWq1VBQUG65557HA5hy+2cq7S0NA0ZMkTh4eGyWq2qUqWKJkyYIMMwcl2vBQsWqEaNGvb6s9ftWvKzTjerltxkvy6nTp2yt82fP1/BwcF68MEH7W2BgYHq0qWLvv76a6Wnp0uStm3bpm3btql3794O/+jq16+fDMO45jmp2b+Dv/zyi5566ikFBgaqVKlS6tOnjzIyMnTq1Cn16NFD/v7+8vf313PPPefwmuR1zuPevXsdPtuz7dixQ507d1bp0qXl7u6uBg0a6JtvvnHoc+HCBY0aNUqRkZFyd3dXmTJl1LRpUy1dulSS7b2U/Zl3+aHslz/vhAkTNGnSJFWqVElWq1Xbtm1TRkaGhg8frvr168vPz09eXl5q1qyZli9fnuN1+fTTT1W/fn35+PjI19dXNWvW1FtvvXXV1xIoCthzBRQj//nPf/Tiiy9qyZIl6tWrV659tm7dqvvuu0+1atXSK6+8IqvVql27dmnVqlWSpDvuuEOvvPKKhg8frt69e6tZs2aSpLvuusu+jOPHj6tdu3bq1q2bHnnkEQUHB1+1rjFjxshisej555/XkSNHNGnSJEVHR2vz5s32PWz5lZmZqfvuu08JCQnq1q2bBg0apNOnT2vp0qXasmWLKlWqlOd6N2vWTL6+vnruuedUsmRJzZw5Uy1bttTKlStzDGwxcOBA+fv7a8SIEdq7d68mTZqkAQMGaN68efmqsV27dmrevLnGjx+vjz76SAMGDJCXl5deeukl/fvf/9aDDz6oGTNmqEePHmrcuLEqVqxYoNdBkj744AP17NlTMTExGjdunM6ePavp06eradOm2rRpk/0L4UMPPaStW7dq4MCBioiI0JEjR7R06VLt379fERERmjRpkgYOHChvb2+99NJLkpRjm/br10+BgYEaPny40tLSJEnr1q3T6tWr1a1bN5UrV0579+7V9OnT1bJlS23btk2enp4FWp8//vhDbdq0UWBgoEaOHKmLFy9qxIgRub6/xowZo2HDhqlLly564okndPToUU2ZMkXNmzfXpk2bCnwu3Zw5c+Tt7a24uDh5e3tr2bJlGj58uFJTU/X666/naxldunRRRESE4uPjtWbNGk2ePFknT57U+++/79Bv2bJl+uyzzzRgwAAFBAQoIiJCycnJuvPOO+3BIDAwUAsXLtTjjz+u1NRUDR48WFLh3/9PPvmk5s+frwEDBqhatWo6fvy4fvnlF23fvl316tXL9TGGYej+++/X8uXL9fjjj6tOnTpavHixnn32WR08eFBvvvmmQ/9ffvlFX375pfr16ycfHx9NnjxZDz30kPbv368yZcrk+brlZ51uVi3ZMjIylJqaqnPnzmn9+vWaMGGCKlSooMqVK9v7bNq0SfXq1ZOLi+P/oRs1aqRZs2bpr7/+Us2aNbVp0yZJcjjaQJLCwsJUrlw5+/xrGThwoEJCQjRq1CitWbNGs2bNUqlSpbR69WqVL19er732mn744Qe9/vrrqlGjRqEO4dy6dauaNGmismXL6oUXXpCXl5c+++wzderUSV988YUeeOABSbZ/KMTHx+uJJ55Qo0aNlJqaqvXr12vjxo2655571KdPHx06dEhLly7VBx98kOtzvffeezp//rx69+4tq9Wq0qVLKzU1Ve+++666d++uXr166fTp0/rvf/+rmJgY/frrr/bD1JcuXaru3burdevWGjdunCRp+/btWrVqlQYNGlTg9QZuKgNAkfHee+8Zkox169bl2cfPz8+oW7eu/f6IESOMy3+V33zzTUOScfTo0TyXsW7dOkOS8d577+WY16JFC0OSMWPGjFzntWjRwn5/+fLlhiSjbNmyRmpqqr39s88+MyQZb731lr2tQoUKRs+ePa+5zNmzZxuSjIkTJ+bom5WVZb8tyRgxYoT9fqdOnQw3Nzdj9+7d9rZDhw4ZPj4+RvPmze1t2a9xdHS0w/Kefvppw9XV1Th16lSO571cz549DUnGa6+9Zm87efKk4eHhYVgsFuPTTz+1t+/YsSNHnVduryvr2rNnj2EYhnH69GmjVKlSRq9evRz6JSUlGX5+fvb2kydPGpKM119//ap1V69e3eF1vvJ5mzZtaly8eNFh3tmzZ3P0T0xMNCQZ77//vr0t+32wfPnyq9bQqVMnw93d3di3b5+9bdu2bYarq6vDa7J3717D1dXVGDNmjMPj//jjD6NEiRI52vNap+zXMq916dOnj+Hp6WmcP3/+qsvL3mb333+/Q3u/fv0MScZvv/1mb5NkuLi4GFu3bnXo+/jjjxuhoaHGsWPHHNq7detm+Pn52esr7Pvfz8/P6N+//1XXo2fPnkaFChXs9xcsWGBIMkaPHu3Qr3PnzobFYjF27drl8Hxubm4Obb/99pshyZgyZcpVnzc/63Szasn2ySefGJLsU4MGDYzff//doY+Xl5fx2GOP5Xjs999/b0gyFi1aZBiGYbz++uuGJGP//v05+jZs2NC48847r1pL9vs1JibGYRs3btzYsFgsxpNPPmlvu3jxolGuXLlcP4ev/P3bs2dPjs/51q1bGzVr1nR4z2dlZRl33XWXERkZaW+rXbu20b59+6vW3b9//1w/y7Kf19fX1zhy5IjDvIsXLxrp6ekObSdPnjSCg4MdXutBgwYZvr6+OT6TgOKAwwKBYsbb2/uqowZm/0f/66+/zvPk9WuxWq2KjY3Nd/8ePXrIx8fHfr9z584KDQ3VDz/8UODn/uKLLxQQEKCBAwfmmJfXcN2ZmZlasmSJOnXqpNtuu83eHhoaqn/961/65ZdflJqa6vCY3r17OyyvWbNmyszM1L59+/JV5xNPPGG/XapUKVWpUkVeXl7q0qWLvb1KlSoqVaqU/ve//+VrmZdbunSpTp06pe7du+vYsWP2ydXVVVFRUfbDaDw8POTm5qYVK1bo5MmTBX6ebL169cox/Pblex0vXLig48ePq3LlyipVqlSeI6blJTMzU4sXL1anTp0cBhq54447FBMT49D3yy+/VFZWlrp06eKw7iEhIYqMjMz1EKJruXxdTp8+rWPHjqlZs2Y6e/asduzYka9l9O/f3+F+9nv0yvd5ixYtVK1aNft9wzD0xRdfqEOHDjIMw2GdYmJilJKSYn89C/P+l2zvwbVr1+rQoUP5Wpfsul1dXfXUU085tA8ZMkSGYWjhwoUO7dHR0Q57zmrVqiVfX99rvr/zs043q5Zsd999t5YuXarPP/9cTz75pEqWLGnfY5vt3LlzslqtOR6bfb7buXPnHH7m1Td7/rU8/vjjDts4KipKhmHo8ccft7e5urqqQYMGhfpMOXHihJYtW6YuXbrYfweOHTum48ePKyYmRjt37tTBgwcl2d5PW7du1c6dOwv8PNkeeughBQYGOrS5urraz7vKysrSiRMndPHiRTVo0MDhM6VUqVJKS0uzH4YIFCeEK6CYOXPmjEOQuVLXrl3VpEkTPfHEEwoODla3bt302WefFSholS1btkAnHl8+apZk+8JUuXLlQp2bs3v3blWpUqVAg3QcPXpUZ8+eVZUqVXLMu+OOO5SVlZXjXJ0rRxL09/eXpHwFFHd39xxfGvz8/FSuXLkcX4D9/PwKFXqyv9S0atVKgYGBDtOSJUt05MgRSbYvdOPGjdPChQsVHBxsP1QxKSmpQM+X22GL586d0/Dhw+3nwAQEBCgwMFCnTp1SSkpKgZZ/9OhRnTt3Lsd7RVKO7bZz504ZhqHIyMgc6759+3b7uhfE1q1b9cADD8jPz0++vr4KDAzUI488Ikn5Xpcra69UqZJcXFxyvM+vfC2PHj2qU6dOadasWTnWJ/ufGNnrVJj3vySNHz9eW7ZsUXh4uBo1aqSRI0de8wv4vn37FBYWluPz5I477rDPv1xuo2/6+/tf8/2dn3W6WbVkCw4OVnR0tDp37qzp06frvvvu0z333OPwe+Ph4WE/r+py2efZZQf27J959c3vodFXrpOfn58kKTw8PEd7YT5Tdu3aJcMwNGzYsBzvwxEjRki69D585ZVXdOrUKd1+++2qWbOmnn32Wf3+++8Fer68DoWeO3euatWqZT+XKzAwUN9//73D72G/fv10++23q127dipXrpwee+yx6zqnDriZOOcKKEb+/vtvpaSkOJwXcCUPDw/99NNPWr58ub7//nstWrRI8+bNU6tWrbRkyZJ8XRy0oOdJ5cfV9jo544KleT2nccXJ8wV5bH6WebXX4XLZYfiDDz6wj152ucu/qA4ePFgdOnTQggULtHjxYg0bNkzx8fFatmyZ6tate/WV+X+5bfOBAwfqvffe0+DBg9W4cWP5+fnJYrGoW7duhd4rmh9ZWVmyWCxauHBhrq+pt7d3gZZ36tQptWjRQr6+vnrllVdUqVIlubu7a+PGjXr++ecLvS55bcsrX8vs5T/yyCPq2bNnro+5/PIKhdGlSxc1a9ZMX331lZYsWaLXX39d48aN05dffql27dpd17KzXc/vjNnMrqVz58566aWX9PXXX6tPnz6SbHu+Dx8+nKNvdltYWJi9X3b7lUHo8OHDatSoUb5qKMjnyvV8pjzzzDM59hZny/7b0rx5c+3evVtff/21lixZonfffVdvvvmmZsyY4bDX/mpy+0z58MMP9eijj6pTp0569tlnFRQUJFdXV8XHxzsMbhIUFKTNmzdr8eLFWrhwoRYuXKj33ntPPXr00Ny5c/P1/ICzEK6AYiT7xOG8/jBmc3FxUevWrdW6dWtNnDhRr732ml566SUtX75c0dHRVz28qDCuPHTEMAzt2rXL4Qujv7+/w0hc2fbt2+dwKF+lSpW0du1aXbhw4apDR18uMDBQnp6e+vPPP3PM27Fjh1xcXHJ86XGW7D1kp06dchiU4cr/zGcf8hQUFJSvYbIrVaqkIUOGaMiQIdq5c6fq1KmjN954wz6yZGG2+fz589WzZ0+98cYb9rbz58/nuh2vJTAwUB4eHrkeZnTldsse4KBixYq6/fbbC/xcV1qxYoWOHz+uL7/8Us2bN7e379mzp0DL2blzp8N/43ft2qWsrKwcI/BdKTAwUD4+PsrMzLzmtizM+z9baGio+vXrp379+unIkSOqV6+exowZk2e4qlChgn788UedPn3aYY9R9mGSFSpUKNDz5yU/63SzaslL9qF7l+89qVOnjn7++WdlZWU5DGqxdu1aeXp62t+b2YMwrF+/3iFIHTp0SH///bd69+59Q2u//DPlcld+pmR/zpYsWTJfnymlS5dWbGysYmNjdebMGTVv3lwjR460h6vCfqbcdttt+vLLLx0en73n7HJubm7q0KGDOnTooKysLPXr108zZ87UsGHDrvoPRsDZOCwQKCaWLVumV199VRUrVtS///3vPPudOHEiR1v2H//sw1ayr2FUmC/JuXn//fcdzgObP3++Dh8+7PClrlKlSlqzZo0yMjLsbd99912Ow/UeeughHTt2TFOnTs3xPHn9V9rV1VVt2rTR119/7XCIVnJysj7++GM1bdpUvr6+hV09U2WHpp9++snelpaWluO/sTExMfbr5Fy4cCHHcrKHjT979myO4cArVaokHx8fh8OUvLy8Cry9XV1dc7zmU6ZMydfw5bktKyYmRgsWLND+/fvt7du3b9fixYsd+j744INydXXVqFGjcjy/YRg6fvx4gZ87+7HZMjIy9PbbbxdoOdlDT2ebMmWKJF1zz5Crq6seeughffHFF9qyZUuO+ZdfAqAw7//MzMwchzYGBQUpLCws10PVst17773KzMzM8VxvvvmmLBaLaXu88rNON6uWY8eO5fo6vvvuu5IcR/zr3LmzkpOT9eWXXzo8/vPPP1eHDh3s51hVr15dVatW1axZsxx+N6ZPny6LxWK/RtaNUqFCBbm6ujp8pkjK8f4OCgpSy5YtNXPmzFz3yF3+Przyd8zb21uVK1fO8ZkiFezvSG6/i2vXrlViYqJDvyuf38XFxf7Puqu9p4GigD1XQBG0cOFC7dixQxcvXlRycrKWLVumpUuXqkKFCvrmm2+uegHRV155RT/99JPat2+vChUq6MiRI3r77bdVrlw5NW3aVJLty3epUqU0Y8YM+fj4yMvLS1FRUYUaLlyy/YezadOmio2NVXJysiZNmqTKlSs7DBf/xBNPaP78+Wrbtq26dOmi3bt368MPP8wxtHSPHj30/vvvKy4uTr/++quaNWumtLQ0/fjjj+rXr586duyYaw2jR4+2X9+rX79+KlGihGbOnKn09HSNHz++UOt1I7Rp00bly5fX448/rmeffVaurq6aPXu2AgMDHUKHr6+vpk+frv/85z+qV6+eunXrZu/z/fffq0mTJpo6dar++usvtW7dWl26dFG1atVUokQJffXVV0pOTla3bt3sy6tfv76mT5+u0aNHq3LlygoKClKrVq2uWut9992nDz74QH5+fqpWrZoSExP1448/5muo69yMGjVKixYtUrNmzdSvXz9dvHhRU6ZMUfXq1R3O56hUqZJGjx6toUOHau/everUqZN8fHy0Z88effXVV+rdu7eeeeaZfD/vXXfdJX9/f/Xs2VNPPfWULBaLPvjggwIfQrZnzx7df//9atu2rRITE/Xhhx/qX//6l2rXrn3Nx44dO1bLly9XVFSUevXqpWrVqunEiRPauHGjfvzxR/s/RQrz/j99+rTKlSunzp07q3bt2vL29taPP/6odevWOex1vFKHDh10991366WXXtLevXtVu3ZtLVmyRF9//bUGDx6c57DvBZWfdbpZtXz44YeaMWOGffCb06dPa/HixVq6dKk6dOjg8DvRuXNn3XnnnYqNjdW2bdsUEBCgt99+W5mZmRo1apTDcl9//XXdf//9atOmjbp166YtW7Zo6tSpeuKJJ+znjd0ofn5+evjhhzVlyhRZLBZVqlRJ3333Xa7nJk6bNk1NmzZVzZo11atXL912221KTk5WYmKi/v77b/3222+SpGrVqqlly5aqX7++SpcurfXr19uH+s9Wv359SdJTTz2lmJgYubq6Onzm5Oa+++7Tl19+qQceeEDt27fXnj17NGPGDFWrVk1nzpyx93viiSd04sQJtWrVSuXKldO+ffs0ZcoU1alT54a/nsB1u3kDEwK4luwhebMnNzc3IyQkxLjnnnuMt956y2G482xXDu2dkJBgdOzY0QgLCzPc3NyMsLAwo3v37sZff/3l8Livv/7aqFatmlGiRAmH4XpbtGhhVK9ePdf68hqK/ZNPPjGGDh1qBAUFGR4eHkb79u0dhtvO9sYbbxhly5Y1rFar0aRJE2P9+vU5lmkYtmGzX3rpJaNixYpGyZIljZCQEKNz584Ow6zriqGoDcMwNm7caMTExBje3t6Gp6encffddxurV6/O9TW+crj7/A4n3rNnT8PLyyvX1ya3161ChQo5hjTesGGDERUVZbi5uRnly5c3Jk6cmOvw4dl1xcTEGH5+foa7u7tRqVIl49FHHzXWr19vGIZhHDt2zOjfv79RtWpVw8vLy/Dz8zOioqKMzz77zGE5SUlJRvv27Q0fHx9Dkv01v9rw/ydPnjRiY2ONgIAAw9vb24iJiTF27NiRY1j9/L52hmEYK1euNOrXr2+4ubkZt912mzFjxow8h6f/4osvjKZNmxpeXl6Gl5eXUbVqVaN///7Gn3/+edXnyO21XLVqlXHnnXcaHh4eRlhYmPHcc88Zixcvzlfd2fVt27bN6Ny5s+Hj42P4+/sbAwYMMM6dO+fQV1KeQ6InJycb/fv3N8LDw+3v69atWxuzZs1y6FfQ9396errx7LPPGrVr1zZ8fHwMLy8vo3bt2sbbb7/tsNwrh2I3DNuQ/08//bQRFhZmlCxZ0oiMjDRef/11hyHBr7ZeeV1i4Ur5WaebUcu6deuMhx9+2ChfvrxhtVoNLy8vo169esbEiRONCxcu5Oh/4sQJ4/HHHzfKlCljeHp6Gi1atMjzUhlfffWVUadOHcNqtRrlypUzXn75ZSMjI+Oar01ev4PZ77srL6uR22fQ0aNHjYceesjw9PQ0/P39jT59+hhbtmzJ9ZIbu3fvNnr06GGEhIQYJUuWNMqWLWvcd999xvz58+19Ro8ebTRq1MgoVaqU4eHhYVStWtUYM2aMw/pcvHjRGDhwoBEYGGhYLBb773D2UOy5XR4iKyvLeO2114wKFSoYVqvVqFu3rvHdd9/leG/Onz/faNOmjREUFGT/nOzTp49x+PDha76egLNZDMMJZ6ICAFBMjBw5UqNGjdLRo0cVEBDg7HIAAEUY51wBAAAAgAkIVwAAAABgAsIVAAAAAJiAc64AAAAAwATsuQIAAAAAExCuAAAAAMAEhCsAAAAAMEEJZxdQFGVlZenQoUPy8fGRxWJxdjkAAAAAnMQwDJ0+fVphYWFycbn6vinCVS4OHTqk8PBwZ5cBAAAAoIg4cOCAypUrd9U+hKtc+Pj4SLK9gL6+vk6uBgAAAICzpKamKjw83J4RroZwlYvsQwF9fX0JVwAAAADydboQA1oAAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJigS4WratGmKiIiQu7u7oqKi9Ouvv+bZ98svv1SDBg1UqlQpeXl5qU6dOvrggw8c+hiGoeHDhys0NFQeHh6Kjo7Wzp07b/RqAAAAALiFOT1czZs3T3FxcRoxYoQ2btyo2rVrKyYmRkeOHMm1f+nSpfXSSy8pMTFRv//+u2JjYxUbG6vFixfb+4wfP16TJ0/WjBkztHbtWnl5eSkmJkbnz5+/WasFAAAA4BZjMQzDcGYBUVFRatiwoaZOnSpJysrKUnh4uAYOHKgXXnghX8uoV6+e2rdvr1dffVWGYSgsLExDhgzRM888I0lKSUlRcHCw5syZo27dul1zeampqfLz81NKSop8fX0Lv3IAAAAAirWCZIMSN6mmXGVkZGjDhg0aOnSovc3FxUXR0dFKTEy85uMNw9CyZcv0559/aty4cZKkPXv2KCkpSdHR0fZ+fn5+ioqKUmJiYq7hKj09Xenp6fb7qamp17NapuvzbR9nl2A3s8NMZ5cAAAAAFElOPSzw2LFjyszMVHBwsEN7cHCwkpKS8nxcSkqKvL295ebmpvbt22vKlCm65557JMn+uIIsMz4+Xn5+fvYpPDz8elYLAAAAwC3I6edcFYaPj482b96sdevWacyYMYqLi9OKFSsKvbyhQ4cqJSXFPh04cMC8YgEAAADcEpx6WGBAQIBcXV2VnJzs0J6cnKyQkJA8H+fi4qLKlStLkurUqaPt27crPj5eLVu2tD8uOTlZoaGhDsusU6dOrsuzWq2yWq3XuTYAAAAAbmVO3XPl5uam+vXrKyEhwd6WlZWlhIQENW7cON/LycrKsp8zVbFiRYWEhDgsMzU1VWvXri3QMgEAAACgIJy650qS4uLi1LNnTzVo0ECNGjXSpEmTlJaWptjYWElSjx49VLZsWcXHx0uynR/VoEEDVapUSenp6frhhx/0wQcfaPr06ZIki8WiwYMHa/To0YqMjFTFihU1bNgwhYWFqVOnTs5aTQAAAAD/cE4PV127dtXRo0c1fPhwJSUlqU6dOlq0aJF9QIr9+/fLxeXSDra0tDT169dPf//9tzw8PFS1alV9+OGH6tq1q73Pc889p7S0NPXu3VunTp1S06ZNtWjRIrm7u9/09QMAAABwa3D6da6KoqJ2nSuGYgcAAACcoyDZoFiOFggAAAAARQ3hCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMUCTC1bRp0xQRESF3d3dFRUXp119/zbPvO++8o2bNmsnf31/+/v6Kjo7O0f/RRx+VxWJxmNq2bXujVwMAAADALczp4WrevHmKi4vTiBEjtHHjRtWuXVsxMTE6cuRIrv1XrFih7t27a/ny5UpMTFR4eLjatGmjgwcPOvRr27atDh8+bJ8++eSTm7E6AAAAAG5RTg9XEydOVK9evRQbG6tq1appxowZ8vT01OzZs3Pt/9FHH6lfv36qU6eOqlatqnfffVdZWVlKSEhw6Ge1WhUSEmKf/P39b8bqAAAAALhFOTVcZWRkaMOGDYqOjra3ubi4KDo6WomJiflaxtmzZ3XhwgWVLl3aoX3FihUKCgpSlSpV1LdvXx0/fjzPZaSnpys1NdVhAgAAAICCcGq4OnbsmDIzMxUcHOzQHhwcrKSkpHwt4/nnn1dYWJhDQGvbtq3ef/99JSQkaNy4cVq5cqXatWunzMzMXJcRHx8vPz8/+xQeHl74lQIAAABwSyrh7AKux9ixY/Xpp59qxYoVcnd3t7d369bNfrtmzZqqVauWKlWqpBUrVqh169Y5ljN06FDFxcXZ76emphKwAAAAABSIU/dcBQQEyNXVVcnJyQ7tycnJCgkJuepjJ0yYoLFjx2rJkiWqVavWVfvedtttCggI0K5du3Kdb7Va5evr6zABAAAAQEE4NVy5ubmpfv36DoNRZA9O0bhx4zwfN378eL366qtatGiRGjRocM3n+fvvv3X8+HGFhoaaUjcAAAAAXMnpowXGxcXpnXfe0dy5c7V9+3b17dtXaWlpio2NlST16NFDQ4cOtfcfN26chg0bptmzZysiIkJJSUlKSkrSmTNnJElnzpzRs88+qzVr1mjv3r1KSEhQx44dVblyZcXExDhlHQEAAAD88zn9nKuuXbvq6NGjGj58uJKSklSnTh0tWrTIPsjF/v375eJyKQNOnz5dGRkZ6ty5s8NyRowYoZEjR8rV1VW///675s6dq1OnTiksLExt2rTRq6++KqvVelPXDQAAAMCtw2IYhuHsIoqa1NRU+fn5KSUlpUicf9Xn2z7OLsFuZoeZzi4BAAAAuGkKkg2cflggAAAAAPwTEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwARFIlxNmzZNERERcnd3V1RUlH799dc8+77zzjtq1qyZ/P395e/vr+jo6Bz9DcPQ8OHDFRoaKg8PD0VHR2vnzp03ejUAAAAA3MKcHq7mzZunuLg4jRgxQhs3blTt2rUVExOjI0eO5Np/xYoV6t69u5YvX67ExESFh4erTZs2OnjwoL3P+PHjNXnyZM2YMUNr166Vl5eXYmJidP78+Zu1WgAAAABuMRbDMAxnFhAVFaWGDRtq6tSpkqSsrCyFh4dr4MCBeuGFF675+MzMTPn7+2vq1Knq0aOHDMNQWFiYhgwZomeeeUaSlJKSouDgYM2ZM0fdunW75jJTU1Pl5+enlJQU+fr6Xt8KmqDPt32cXYLdzA4znV0CAAAAcNMUJBs4dc9VRkaGNmzYoOjoaHubi4uLoqOjlZiYmK9lnD17VhcuXFDp0qUlSXv27FFSUpLDMv38/BQVFZXnMtPT05WamuowAQAAAEBBODVcHTt2TJmZmQoODnZoDw4OVlJSUr6W8fzzzyssLMweprIfV5BlxsfHy8/Pzz6Fh4cXdFUAAAAA3OKcfs7V9Rg7dqw+/fRTffXVV3J3dy/0coYOHaqUlBT7dODAAROrBAAAAHArKOHMJw8ICJCrq6uSk5Md2pOTkxUSEnLVx06YMEFjx47Vjz/+qFq1atnbsx+XnJys0NBQh2XWqVMn12VZrVZZrdZCrgUAAAAAOHnPlZubm+rXr6+EhAR7W1ZWlhISEtS4ceM8Hzd+/Hi9+uqrWrRokRo0aOAwr2LFigoJCXFYZmpqqtauXXvVZQIAAADA9XDqnitJiouLU8+ePdWgQQM1atRIkyZNUlpammJjYyVJPXr0UNmyZRUfHy9JGjdunIYPH66PP/5YERER9vOovL295e3tLYvFosGDB2v06NGKjIxUxYoVNWzYMIWFhalTp07OWk0AAAAA/3BOD1ddu3bV0aNHNXz4cCUlJalOnTpatGiRfUCK/fv3y8Xl0g626dOnKyMjQ507d3ZYzogRIzRy5EhJ0nPPPae0tDT17t1bp06dUtOmTbVo0aLrOi8LAAAAAK7G6de5Koq4zlXeuM4VAAAAbiXF5jpXAAAAAPBPQbgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExQorAPTEtL08qVK7V//35lZGQ4zHvqqaeuuzAAAAAAKE4KFa42bdqke++9V2fPnlVaWppKly6tY8eOydPTU0FBQYQrAAAAALecQh0W+PTTT6tDhw46efKkPDw8tGbNGu3bt0/169fXhAkTzK4RAAAAAIq8QoWrzZs3a8iQIXJxcZGrq6vS09MVHh6u8ePH68UXXzS7RgAAAAAo8goVrkqWLCkXF9tDg4KCtH//fkmSn5+fDhw4YF51AAAAAFBMFOqcq7p162rdunWKjIxUixYtNHz4cB07dkwffPCBatSoYXaNAAAAAFDkFWrP1WuvvabQ0FBJ0pgxY+Tv76++ffvq6NGjmjVrlqkFAgAAAEBxUKg9Vw0aNLDfDgoK0qJFi0wrCAAAAACKIy4iDAAAAAAmyPeeq3r16ikhIUH+/v6qW7euLBZLnn03btxoSnEAAAAAUFzkO1x17NhRVqtVktSpU6cbVQ8AAAAAFEv5DlcjRozI9TYAAAAAoJDnXK1bt05r167N0b527VqtX7/+uosCAAAAgOKmUOGqf//+uV4s+ODBg+rfv/91FwUAAAAAxU2hwtW2bdtUr169HO1169bVtm3brrsoAAAAAChuChWurFarkpOTc7QfPnxYJUoU6tJZAAAAAFCsFSpctWnTRkOHDlVKSoq97dSpU3rxxRd1zz33mFYcAAAAABQXhdrNNGHCBDVv3lwVKlRQ3bp1JUmbN29WcHCwPvjgA1MLBAAAAIDioFDhqmzZsvr999/10Ucf6bfffpOHh4diY2PVvXt3lSxZ0uwaAQAAAKDIK/QJUl5eXurdu7eZtQAAAABAsVXocLVz504tX75cR44cUVZWlsO84cOHX3dhAAAAAFCcFCpcvfPOO+rbt68CAgIUEhIii8Vin2exWAhXAAAAAG45hQpXo0eP1pgxY/T888+bXQ8AAAAAFEuFGor95MmTevjhh82uBQAAAACKrUKFq4cfflhLliwxuxYAAAAAKLYKdVhg5cqVNWzYMK1Zs0Y1a9bMMfz6U089ZUpxAAAAAFBcFCpczZo1S97e3lq5cqVWrlzpMM9isRCuAAAAANxyChWu9uzZY3YdAAAAAFCsFeqcq2wZGRn6888/dfHiRbPqAQAAAIBiqVDh6uzZs3r88cfl6emp6tWra//+/ZKkgQMHauzYsaYWCAAAAADFQaHC1dChQ/Xbb79pxYoVcnd3t7dHR0dr3rx5phUHAAAAAMVFoc65WrBggebNm6c777xTFovF3l69enXt3r3btOIAAAAAoLgo1J6ro0ePKigoKEd7WlqaQ9gCAAAAgFtFocJVgwYN9P3339vvZweqd999V40bNzanMgAAAAAoRgp1WOBrr72mdu3aadu2bbp48aLeeustbdu2TatXr85x3SsAAAAAuBUUas9V06ZNtXnzZl28eFE1a9bUkiVLFBQUpMTERNWvX9/sGgEAAACgyCvUnitJqlSpkt555x0zawEAAACAYqtQ4Sr7ulZ5KV++fKGKAQAAAIDiqlDhKiIi4qqjAmZmZha6IAAAAAAojgoVrjZt2uRw/8KFC9q0aZMmTpyoMWPGmFIYAAAAABQnhQpXtWvXztHWoEEDhYWF6fXXX9eDDz543YUBAAAAQHFSqNEC81KlShWtW7euQI+ZNm2aIiIi5O7urqioKP3666959t26daseeugh+2GJkyZNytFn5MiRslgsDlPVqlULuioAAAAAUCCFClepqakOU0pKinbs2KGXX35ZkZGR+V7OvHnzFBcXpxEjRmjjxo2qXbu2YmJidOTIkVz7nz17VrfddpvGjh2rkJCQPJdbvXp1HT582D798ssvBV5HAAAAACiIQh0WWKpUqRwDWhiGofDwcH366af5Xs7EiRPVq1cvxcbGSpJmzJih77//XrNnz9YLL7yQo3/Dhg3VsGFDScp1frYSJUpcNXwBAAAAgNkKFa6WLVvmEK5cXFwUGBioypUrq0SJ/C0yIyNDGzZs0NChQx2WEx0drcTExMKUZbdz506FhYXJ3d1djRs3Vnx8/FWHh09PT1d6err9fmpq6nU9PwAAAIBbT6HCVcuWLa/7iY8dO6bMzEwFBwc7tAcHB2vHjh2FXm5UVJTmzJmjKlWq6PDhwxo1apSaNWumLVu2yMfHJ9fHxMfHa9SoUYV+TgAAAAAo1DlX8fHxmj17do722bNna9y4cddd1PVo166dHn74YdWqVUsxMTH64YcfdOrUKX322Wd5Pmbo0KFKSUmxTwcOHLiJFQMAAAD4JyhUuJo5c2auI/BVr15dM2bMyNcyAgIC5OrqquTkZIf25ORkU8+XKlWqlG6//Xbt2rUrzz5Wq1W+vr4OEwAAAAAURKHCVVJSkkJDQ3O0BwYG6vDhw/lahpubm+rXr6+EhAR7W1ZWlhISEtS4cePClJWrM2fOaPfu3bnWCwAAAABmKVS4Cg8P16pVq3K0r1q1SmFhYfleTlxcnN555x3NnTtX27dvV9++fZWWlmYfPbBHjx4OA15kZGRo8+bN2rx5szIyMnTw4EFt3rzZYa/UM888o5UrV2rv3r1avXq1HnjgAbm6uqp79+6FWVUAAAAAyJdCDWjRq1cvDR48WBcuXFCrVq0kSQkJCXruuec0ZMiQfC+na9euOnr0qIYPH66kpCTVqVNHixYtsg9ysX//frm4XMp/hw4dUt26de33J0yYoAkTJqhFixZasWKFJOnvv/9W9+7ddfz4cQUGBqpp06Zas2aNAgMDC7OqAAAAAJAvFsMwjII+yDAMvfDCC5o8ebIyMjIkSe7u7nr++ec1fPhw04u82VJTU+Xn56eUlJQicf5Vn2/7OLsEu5kdZjq7BAAAAOCmKUg2KNSeK4vFonHjxmnYsGHavn27PDw8FBkZKavVWqiCAQAAAKC4K9Q5V9mSkpJ04sQJVapUSVarVYXYCQYAAAAA/wiFClfHjx9X69atdfvtt+vee++1jxD4+OOPF+icKwAAAAD4pyhUuHr66adVsmRJ7d+/X56envb2rl27atGiRaYVBwAAAADFRaHOuVqyZIkWL16scuXKObRHRkZq3759phQGAAAAAMVJofZcpaWlOeyxynbixAkGtQAAAABwSypUuGrWrJnef/99+32LxaKsrCyNHz9ed999t2nFAQAAAEBxUajDAsePH6/WrVtr/fr1ysjI0HPPPaetW7fqxIkTWrVqldk1AgAAAECRV6g9VzVq1NBff/2lpk2bqmPHjkpLS9ODDz6oTZs2qVKlSmbXCAAAAABFXoH3XF24cEFt27bVjBkz9NJLL92ImgAAAACg2CnwnquSJUvq999/vxG1AAAAAECxVajDAh955BH997//NbsWAAAAACi2CjWgxcWLFzV79mz9+OOPql+/vry8vBzmT5w40ZTiAAAAAKC4KFC4+t///qeIiAht2bJF9erVkyT99ddfDn0sFot51QEAAABAMVGgcBUZGanDhw9r+fLlkqSuXbtq8uTJCg4OviHFAQAAAEBxUaBzrgzDcLi/cOFCpaWlmVoQAAAAABRHhRrQItuVYQsAAAAAblUFClcWiyXHOVWcYwUAAAAABTznyjAMPfroo7JarZKk8+fP68knn8wxWuCXX35pXoUAAAAAUAwUKFz17NnT4f4jjzxiajEAAAAAUFwVKFy99957N6oOAAAAACjWrmtACwAAAACADeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMIHTw9W0adMUEREhd3d3RUVF6ddff82z79atW/XQQw8pIiJCFotFkyZNuu5lAgAAAIAZnBqu5s2bp7i4OI0YMUIbN25U7dq1FRMToyNHjuTa/+zZs7rttts0duxYhYSEmLJMAAAAADCDU8PVxIkT1atXL8XGxqpatWqaMWOGPD09NXv27Fz7N2zYUK+//rq6desmq9VqyjIBAAAAwAxOC1cZGRnasGGDoqOjLxXj4qLo6GglJiYWmWUCAAAAQH6UcNYTHzt2TJmZmQoODnZoDw4O1o4dO27qMtPT05Wenm6/n5qaWqjnBwAAAHDrcvqAFkVBfHy8/Pz87FN4eLizSwIAAABQzDgtXAUEBMjV1VXJyckO7cnJyXkOVnGjljl06FClpKTYpwMHDhTq+QEAAADcupwWrtzc3FS/fn0lJCTY27KyspSQkKDGjRvf1GVarVb5+vo6TAAAAABQEE4750qS4uLi1LNnTzVo0ECNGjXSpEmTlJaWptjYWElSjx49VLZsWcXHx0uyDVixbds2++2DBw9q8+bN8vb2VuXKlfO1TAAAAAC4EZwarrp27aqjR49q+PDhSkpKUp06dbRo0SL7gBT79++Xi8ulnWuHDh1S3bp17fcnTJigCRMmqEWLFlqxYkW+lgkAAAAAN4LFMAzD2UUUNampqfLz81NKSkqROESwz7d9nF2C3cwOM51dAgAAAHDTFCQbMFogAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJigS4WratGmKiIiQu7u7oqKi9Ouvv161/+eff66qVavK3d1dNWvW1A8//OAw/9FHH5XFYnGY2rZteyNXAQAAAMAtzunhat68eYqLi9OIESO0ceNG1a5dWzExMTpy5Eiu/VevXq3u3bvr8ccf16ZNm9SpUyd16tRJW7ZscejXtm1bHT582D598sknN2N1AAAAANyinB6uJk6cqF69eik2NlbVqlXTjBkz5OnpqdmzZ+fa/6233lLbtm317LPP6o477tCrr76qevXqaerUqQ79rFarQkJC7JO/v//NWB0AAAAAtyinhquMjAxt2LBB0dHR9jYXFxdFR0crMTEx18ckJiY69JekmJiYHP1XrFihoKAgValSRX379tXx48fNXwEAAAAA+H8lnPnkx44dU2ZmpoKDgx3ag4ODtWPHjlwfk5SUlGv/pKQk+/22bdvqwQcfVMWKFbV79269+OKLateunRITE+Xq6ppjmenp6UpPT7ffT01NvZ7VAgAAAHALcmq4ulG6detmv12zZk3VqlVLlSpV0ooVK9S6desc/ePj4zVq1KibWSIAAACAfxinHhYYEBAgV1dXJScnO7QnJycrJCQk18eEhIQUqL8k3XbbbQoICNCuXbtynT906FClpKTYpwMHDhRwTQAAAADc6pwartzc3FS/fn0lJCTY27KyspSQkKDGjRvn+pjGjRs79JekpUuX5tlfkv7++28dP35coaGhuc63Wq3y9fV1mAAAAACgIJw+WmBcXJzeeecdzZ07V9u3b1ffvn2Vlpam2NhYSVKPHj00dOhQe/9BgwZp0aJFeuONN7Rjxw6NHDlS69ev14ABAyRJZ86c0bPPPqs1a9Zo7969SkhIUMeOHVW5cmXFxMQ4ZR0BAAAA/PM5/Zyrrl276ujRoxo+fLiSkpJUp04dLVq0yD5oxf79++XicikD3nXXXfr444/18ssv68UXX1RkZKQWLFigGjVqSJJcXV31+++/a+7cuTp16pTCwsLUpk0bvfrqq7JarU5ZRwAAAAD/fBbDMAxnF1HUpKamys/PTykpKUXiEME+3/Zxdgl2MzvMdHYJAAAAwE1TkGzg9MMCAQAAAOCfgHAFAAAAACZw+jlXMIFhqMTFLJXIyFTJC5kqcSFTJTMuqsSFLBkuFmVlT64uDrfPe5TUBTdXyWJx9hoAAAAAxR7hqig7dkxasEAxv2yWV+p5eZ1Jl9fpdHmnnpfnmXR5nz4vj7QMuWVkFvopMl0tOufppnOebjrv6abzHiV1zstNp33dlVLaUymlvZTi72m77e8ppadLDAwCAAAA5MCAFrkoMgNabNki1azpvOfPS3CwVLmybapUyfF26dLOrg4AAAAwTUGyAXuuirIyZfKclW4toTQfq856WZVhLaGLJV11wc1VF0q66mL2z5KusmQZcs3MkkuW4XDbNTNL1vMX5H72gjzSMuR+LkMeZy+o5IV87AVLTrZNq1blnBcQINWqZZtq1rT9rFZN8vS8jhcCAAAAKPoIV0VZQIA0a5Zm/O9zpflYdcbHXWk+VqX5WHXR7cZsuhIXMuWRliGfU+fkd/KsSp1Ik9+Js/I7eVZ+J86qvkKlPXukw4dzX8CxY9KyZbYpm8UiRUZKdepIjRpJUVFSvXoELgAAAPyjcFhgLorMYYH/r0he5yotTdq92zbt2nVp2rZNSkq69oJcXW17tqKibNOdd0pVqzK4BgAAAIoUDgvEjefldenwvysdOSL98Yf0+++Xfm7dKp0/f6lPZqa0ebNtmvn/gS0oSGreXGrRwjZVry65cLUAAAAAFA+EK5gvKEhq3do2Zbt40bZXa+3aS9PWrdLlO06PHJHmz7dNku2cs+bNpZYtpXvuYc8WAAAAijTCFW6OEiUu7enq1cvWdvq0tH69LWitWiX99JOUmnrpMcePS199ZZskKTxciomxTa1bS/7+N389AAAAgDwQruA8Pj7S3XfbJsl2qOBvv0krV0orVkg//yydPHmp/4ED0rvv2iYXF9u5WjEx0n332QbIYK8WAAAAnIgTWlB0uLraQtLTT0tff20beXDzZmnCBNthgZdfvDgrS0pMlEaOlBo0sO3V6ttXWrjQ8dwuAAAA4CYhXKHocnGRateWhgyRliyRTpywhafBg6U77nDse/CgNGOGdO+9tiHsH3xQmjPHFtAAAACAm4DDAlF8eHpKbdvaJknav1/64Qfp22+lhAQpPd3WnpZ26VwtV1fbgBidO0udOkkhIc6qHgAAAP9w7LlC8VW+vPTkk9L3318a/CI2VgoMvNQnM9MWvPr2lcLCbKMPTp4s/f238+oGAADAPxLhCv8MXl62PVOzZ0uHD0urV0vPPivddtulPoZhGyRj0CDbOVp33WULWocPO61sAAAA/HMQrvDP4+oqNW4sjR8v7dolbdokvfSS7TpZl0tMtAWtcuWkVq2kWbNse8AAAACAQiBc4Z/NYpHq1JFGj5a2b7dduPiVV6QaNS71ycqSli+X+vSxnZN1773SBx9IZ844rWwAAAAUP4Qr3FqqVZOGDZP++EPassV2u3LlS/MvXrSNSNijhxQUJP3rX7Zzui5ccF7NAAAAKBYIV7h1Va9u24v111/Shg22c7TCwy/NP3dO+uQT20WKw8KkAQOkNWts524BAAAAVyBcARaL7eLF48dLe/dKv/xiG12wdOlLfY4dk6ZNs53LFRlpC2X/+5/TSgYAAEDRQ7gCLufiIjVpIr39tm0Uwa+/lrp0kdzdL/XZvVsaMUKqVMk2tPu770opKc6rGQAAAEUC4QrIi5ubdP/90rx5UnKy9N57tlEFLZZLfX7+WerVyzYQRrdutosaX7zovJoBAADgNIQrID98faVHH7VdkHjfPik+Xrrjjkvzz5+3hbD27W3nbT37rG3ADAAAANwyCFdAQYWHSy+8YBvWfd06aeBAKSDg0vykJGnCBKlmTal+fWnKFNs5WwAAAPhHI1wBhWWxSA0aSJMnS4cO2c7PevBBqWTJS302bpSeeso22uADD9j6MKw7AADAPxLhCjBDyZK287O++MI2EMaUKbbgle3CBWnBAqlTJ6lsWenpp6XffnNWtQAAALgBCFeA2cqUsV0Ta90623lXzz4rhYZemn/0qDRpklSnjlS3rvTWW7Y2AAAAFGuEK+BGql7ddv2s/fttIwl27SpZrZfmb94sDR5sO2ywY0fpyy+ljAxnVQsAAIDrQLgCboYSJaR27aRPP7UdNjh9uhQVdWn+xYvSN99IDz1kC1oDB0rr10uG4byaAQAAUCCEK+Bm8/eXnnxSWrNG2r5dev55W6DKdvy4NHWq1LChVKOGbc/XoUPOqxcAAAD5QrgCnKlqVWnsWNthg4sWSd27S+7ul+Zv22YLX+HhUkyM9NFHUlqa8+oFAABAnghXQFHg6moLTx9/bLtO1qxZUpMml+ZnZUlLlkiPPCKFhEixsdLy5bZ2AAAAFAmEK6Co8fOTevWSfvlF+usvadgwKSLi0vwzZ6Q5c6RWrWztQ4faLmgMAAAApyJcAUVZZKT0yivS7t3STz9JTzwh+fpemn/ggO2wwho1bMO6v/EG52cBAAA4CeEKKA5cXKRmzaR33rEdNjhvnnTvvbbDCbNt3iw984xUrpwUHW3bu5Wa6qyKAQAAbjmEK6C48fCQunSRvv/etpdq8mSpUaNL8w1DSkiwnZcVFGQb3n3+fOncOefVDAAAcAsgXAHFWVCQ7ZpYa9fazs8aMUKqVOnS/PR024WJH35YCg6WevSwXcz4wgXn1QwAAPAPRbgC/ikiI6WRI6WdO6XERFvoCg6+NP/0aemDD6T27aXQUKlPH+nHH20XMAYAAMB1I1wB/zQWi3TnnbbDBf/+W1q6VHrsMdsohNmOH7cN937PPZeCVkICQQsAAOA6EK6Af7ISJWyDW/z3v1JysrRggdS1q+28rWzHjtmCVnS04x4tDh0EAAAoEMIVcKuwWqWOHaVPP5WOHpU++0zq3Dn3oHXPPbZDCnv2tAWys2edVjYAAEBxQbgCbkVeXrZBLj7/PO+gdfKk9P770gMPSIGBtlEHP/xQOnXKaWUDAAAUZYQr4FaXW9Dq3l3y8bnU5+xZ26iD//mPLWi1aiVNmmS7uDEAAAAkEa4AXC47aH38sS1o/fCD9MQTtkCV7eJFafly6emnpcqVpWrVpOefl375RcrMdF7tAAAATka4ApA7q1Vq10565x3p8GFp5Upp0CDpttsc+23fLo0fLzVrZjtP61//sh1OmJzsnLoBAACchHAF4NpcXaXmzW2HAu7aJW3dKo0dKzVpIrlc9jFy/Lj0ySe2gTBCQqT69aWXX7bt1WKYdwAA8A9HuAJQMBaL46GAycnS3Lm2ATF8fR37btwojRlj26sVECB16iRNnSrt2CEZhlPKBwAAuFFKOLsAAMVcQIDUo4dtunBBWrNGWrhQWrRI2rTpUr+UFOnrr22TJJUtK7Vubbu+VuvWUliYc+oHAAAwCXuuAJinZEnbXqrXXrPttTp0SJozx3bh4jJlHPsePGg7N6tHD1vQuv12qVcv23DvBw44pXwAAIDrwZ4rADdOaKjt/KuePaWsLOm336SEBOnHH6WffpLOnbvUd+dO2/Tuu7b7ERFSixa2qUkTKTLSdkgiAABAEUW4AnBzuLhIdevapmeekdLTpcREW9Bavlxat852WGG2vXtt09y5tvsBAVLjxtJdd9mmBg0kT09nrAkAAECuCFcAnMNqlVq2tE2S7ULFa9bYhnxfudJ2Oz39Uv9jx6Rvv7VNklSihFSnjtSokdSwoW2qWtU2siEAAIATEK4AFA2enlKrVrZJsgWrX3+Vfv7Ztodr9WrpxIlL/S9elNavt03ZvL2levUuha169aRKlRyHiwcAALhBCFcAiiar1TY4RrNmtvuGIf31ly1kZU/btjk+5swZ27lcP/10qc3bW6pVy3Y4Yp06tqlGDcnd/WatCQAAuEUQrgAUDxaLVKWKbYqNtbWdOiVt2GDbe7VunW3av9/xcWfOXApj2VxdbaMTVq9uC1rZPytXth1uCAAAUAh8iwBQfJUqZbtGVuvWl9qSky8dLrh5s23au9fxcZmZ0vbttmn+/Evtbm6287buuMMW4qpWtf28/XbbHjAAAICrIFwB+GcJDpbat7dN2U6etA0Dnx22Nm+2BauMDMfHZmRIv/9um65UtuyloFWp0qXpttsIXgAAQBLhCsCtwN/fcWRCyTYgxu7d0pYt0tatl37+9Zdt3pUOHrRNy5blnBcUdCloVajgOJUvz5DxAADcIghXAG5NJUpcOofroYcutWdkSP/7n/Tnn5emHTtsP48fz31ZR47YpsTE3OcHBtpCVrlytj1gZcs63i5bVvLxMX8dAQDATUW4AoDLZZ93VbVqznnHj0u7dtn2eO3ebQth2bcPHcp7mUeP2qYNG/Lu4+UlhYTYDmsMCbk0BQfbwtnlU6lSDC8PALgh+nzbx9kl2M3sMNPZJRRYkQhX06ZN0+uvv66kpCTVrl1bU6ZMUaNGjfLs//nnn2vYsGHau3evIiMjNW7cON177732+YZhaMSIEXrnnXd06tQpNWnSRNOnT1dkZOTNWB0A/1RlytimqKic886elfbty3s6dEjKysp72Wlpl4Latbi6SgEBtqBVpoxUunTuk7+/5OdnC2N+frbJza3Qqw8AMF9RCjO4fk4PV/PmzVNcXJxmzJihqKgoTZo0STExMfrzzz8VFBSUo//q1avVvXt3xcfH67777tPHH3+sTp06aePGjapRo4Ykafz48Zo8ebLmzp2rihUratiwYYqJidG2bdvkzrVtANwInp62UQbvuCP3+Rcv2kYyPHhQ+vvvS+dwZd9OTpaSkmyDb1xLZqatf3Jy4er085N8fW2Tj8+ln9m3vb1te9Ku/Jk9eXpKHh6XfpYsaRsqHwCAW5zFMAzDmQVERUWpYcOGmjp1qiQpKytL4eHhGjhwoF544YUc/bt27aq0tDR999139rY777xTderU0YwZM2QYhsLCwjRkyBA988wzkqSUlBQFBwdrzpw56tat2zVrSk1NlZ+fn1JSUuTr62vSmhZeUfqPRnHcPQsUK+npl4JW9nTs2KVDC6+c0tOdXbFtT1p20HJ3d5yy26xWx8nNLef9kiVtP7On7PslS9rOkStZMvfbuU2urpemK+9fPhEKAThZUfqeV9QUle+dBckGTt1zlZGRoQ0bNmjo0KH2NhcXF0VHRysxjxPDExMTFRcX59AWExOjBQsWSJL27NmjpKQkRUdH2+f7+fkpKipKiYmJ+QpXAOA0Vqtt8Ivy5fPX/9w56cQJ23T8+KXbJ07YLrKckmL7eeXt06dtkxn/X8vMvLS84ig7aLm4ON6+2mSx5Lx9+c8rb1+tLbdJunpbbrev/Hl5cMyr35Xzc7t/rb7OnFdYhGoUIb0PXeV83Fvd+w9L48dLFSs6u5J8c2q4OnbsmDIzMxUcHOzQHhwcrB07duT6mKSkpFz7JyUl2ednt+XV50rp6elKv+y/vykpKZJsKbUoyDibce1ON0lReU0AXCb7kL4KFQr2OMOwnet15oxtSk21/cxuO3vWNmXfTkuz/Tx/3vbz3LlLU/b99HTbdP580dirlh+ZmbYJAJyAEQHylqo90qBBtvOLnVnH/3//zc8Bf04/56ooiI+P16hRo3K0h4eHO6Gaom2O5ji7BAAAANwqmjVzdgV2p0+flp+f31X7ODVcBQQEyNXVVclXnJSdnJyskJCQXB8TEhJy1f7ZP5OTkxUaGurQp06dOrkuc+jQoQ6HGmZlZenEiRMqU6aMLE4+dCA1NVXh4eE6cOBAkTj/C9fGNite2F7FD9us+GGbFS9sr+KHbXZjGYah06dPKyws7Jp9nRqu3NzcVL9+fSUkJKhTp06SbMEmISFBAwYMyPUxjRs3VkJCggYPHmxvW7p0qRo3bixJqlixokJCQpSQkGAPU6mpqVq7dq369u2b6zKtVqusVqtDW6lSpa5r3czm6+vLL0sxwzYrXthexQ/brPhhmxUvbK/ih21241xrj1U2px8WGBcXp549e6pBgwZq1KiRJk2apLS0NMXGxkqSevToobJlyyo+Pl6SNGjQILVo0UJvvPGG2rdvr08//VTr16/XrFmzJEkWi0WDBw/W6NGjFRkZaR+KPSwszB7gAAAAAMBsTg9XXbt21dGjRzV8+HAlJSWpTp06WrRokX1Aiv3798vFxcXe/6677tLHH3+sl19+WS+++KIiIyO1YMEC+zWuJOm5555TWlqaevfurVOnTqlp06ZatGgR17gCAAAAcMM4PVxJ0oABA/I8DHDFihU52h5++GE9/PDDeS7PYrHolVde0SuvvGJWiU5jtVo1YsSIHIctouhimxUvbK/ih21W/LDNihe2V/HDNis6nH4RYQAAAAD4J3C5dhcAAAAAwLUQrgAAAADABIQrAAAAADAB4QoAAAAATEC4KuKmTZumiIgIubu7KyoqSr/++quzS8L/++mnn9ShQweFhYXJYrFowYIFDvMNw9Dw4cMVGhoqDw8PRUdHa+fOnc4pFoqPj1fDhg3l4+OjoKAgderUSX/++adDn/Pnz6t///4qU6aMvL299dBDDyk5OdlJFd/apk+frlq1atkviNm4cWMtXLjQPp9tVbSNHTvWft3JbGyzomXkyJGyWCwOU9WqVe3z2V5F08GDB/XII4+oTJky8vDwUM2aNbV+/Xr7fL57OB/hqgibN2+e4uLiNGLECG3cuFG1a9dWTEyMjhw54uzSICktLU21a9fWtGnTcp0/fvx4TZ48WTNmzNDatWvl5eWlmJgYnT9//iZXCklauXKl+vfvrzVr1mjp0qW6cOGC2rRpo7S0NHufp59+Wt9++60+//xzrVy5UocOHdKDDz7oxKpvXeXKldPYsWO1YcMGrV+/Xq1atVLHjh21detWSWyromzdunWaOXOmatWq5dDONit6qlevrsOHD9unX375xT6P7VX0nDx5Uk2aNFHJkiW1cOFCbdu2TW+88Yb8/f3tffjuUQQYKLIaNWpk9O/f334/MzPTCAsLM+Lj451YFXIjyfjqq6/s97OysoyQkBDj9ddft7edOnXKsFqtxieffOKECnGlI0eOGJKMlStXGoZh2z4lS5Y0Pv/8c3uf7du3G5KMxMREZ5WJy/j7+xvvvvsu26oIO336tBEZGWksXbrUaNGihTFo0CDDMPj9KopGjBhh1K5dO9d5bK+i6fnnnzeaNm2a53y+exQN7LkqojIyMrRhwwZFR0fb21xcXBQdHa3ExEQnVob82LNnj5KSkhy2n5+fn6Kioth+RURKSookqXTp0pKkDRs26MKFCw7brGrVqipfvjzbzMkyMzP16aefKi0tTY0bN2ZbFWH9+/dX+/btHbaNxO9XUbVz506FhYXptttu07///W/t379fEturqPrmm2/UoEEDPfzwwwoKClLdunX1zjvv2Ofz3aNoIFwVUceOHVNmZqaCg4Md2oODg5WUlOSkqpBf2duI7Vc0ZWVlafDgwWrSpIlq1KghybbN3NzcVKpUKYe+bDPn+eOPP+Tt7S2r1aonn3xSX331lapVq8a2KqI+/fRTbdy4UfHx8Tnmsc2KnqioKM2ZM0eLFi3S9OnTtWfPHjVr1kynT59mexVR//vf/zR9+nRFRkZq8eLF6tu3r5566inNnTtXEt89iooSzi4AAG62/v37a8uWLQ7nF6DoqVKlijZv3qyUlBTNnz9fPXv21MqVK51dFnJx4MABDRo0SEuXLpW7u7uzy0E+tGvXzn67Vq1aioqKUoUKFfTZZ5/Jw8PDiZUhL1lZWWrQoIFee+01SVLdunW1ZcsWzZgxQz179nRydcjGnqsiKiAgQK6urjlG5klOTlZISIiTqkJ+ZW8jtl/RM2DAAH333Xdavny5ypUrZ28PCQlRRkaGTp065dCfbeY8bm5uqly5surXr6/4+HjVrl1bb731FtuqCNqwYYOOHDmievXqqUSJEipRooRWrlypyZMnq0SJEgoODmabFXGlSpXS7bffrl27dvE7VkSFhoaqWrVqDm133HGH/XBOvnsUDYSrIsrNzU3169dXQkKCvS0rK0sJCQlq3LixEytDflSsWFEhISEO2y81NVVr165l+zmJYRgaMGCAvvrqKy1btkwVK1Z0mF+/fn2VLFnSYZv9+eef2r9/P9usiMjKylJ6ejrbqghq3bq1/vjjD23evNk+NWjQQP/+97/tt9lmRduZM2e0e/duhYaG8jtWRDVp0iTHJUT++usvVahQQRLfPYoMZ4+ogbx9+umnhtVqNebMmWNs27bN6N27t1GqVCkjKSnJ2aXBsI2KtWnTJmPTpk2GJGPixInGpk2bjH379hmGYRhjx441SpUqZXz99dfG77//bnTs2NGoWLGice7cOSdXfmvq27ev4efnZ6xYscI4fPiwfTp79qy9z5NPPmmUL1/eWLZsmbF+/XqjcePGRuPGjZ1Y9a3rhRdeMFauXGns2bPH+P33340XXnjBsFgsxpIlSwzDYFsVB5ePFmgYbLOiZsiQIcaKFSuMPXv2GKtWrTKio6ONgIAA48iRI4ZhsL2Kol9//dUoUaKEMWbMGGPnzp3GRx99ZHh6ehoffvihvQ/fPZyPcFXETZkyxShfvrzh5uZmNGrUyFizZo2zS8L/W758uSEpx9SzZ0/DMGxDog4bNswIDg42rFar0bp1a+PPP/90btG3sNy2lSTjvffes/c5d+6c0a9fP8Pf39/w9PQ0HnjgAePw4cPOK/oW9thjjxkVKlQw3NzcjMDAQKN169b2YGUYbKvi4MpwxTYrWrp27WqEhoYabm5uRtmyZY2uXbsau3btss9nexVN3377rVGjRg3DarUaVatWNWbNmuUwn+8ezmcxDMNwzj4zAAAAAPjn4JwrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAIJ/Wr1+vN998U1lZWc4uBQBQBBGuAAD/eBaLRQsWLLiuvkePHtXDDz+sGjVqyMXFnD+fzZs318cff3xdy7jzzjv1xRdfmFIPAOD6EK4AADfNo48+KovFIovFIjc3N1WuXFmvvPKKLl68eEOf9/Dhw2rXrl2h+2ZlZek///mPRowYoXvuuceUmr755hslJyerW7du9ra4uDiVLl1a4eHh+uijjxz6f/755+rQoUOO5bz88st64YUX2JsGAEWAxTAMw9lFAABuDY8++qiSk5P13nvvKT09XT/88IP69++vMWPGaOjQoTn6Z2RkyM3NzQmV3njR0dGKjo7WCy+8IEn69ttv1atXL3333XfauXOnHnvsMR04cEABAQFKSUlRw4YN9eOPP6p8+fIOy8nMzFTZsmX13//+V+3bt3fGqgAA/h97rgAAN5XValVISIgqVKigvn37Kjo6Wt98840kW/jq1KmTxowZo7CwMFWpUkWSdODAAXXp0kWlSpVS6dKl1bFjR+3du9dhubNnz1b16tVltVoVGhqqAQMG2OddfqhfRkaGBgwYoNDQULm7u6tChQqKj4/Pta8k/fHHH2rVqpU8PDxUpkwZ9e7dW2fOnLHPz655woQJCg0NVZkyZdS/f39duHAhz9fg6NGjWrZsmcOeqO3bt6tly5Zq0KCBunfvLl9fX+3Zs0eS9Nxzz6lv3745gpUkubq66t5779Wnn356jVceAHCjEa4AAE7l4eGhjIwM+/2EhAT9+eefWrp0qb777jtduHBBMTEx8vHx0c8//6xVq1bJ29tbbdu2tT9u+vTp6t+/v3r37q0//vhD33zzjSpXrpzr802ePFnffPONPvvsM/3555/66KOPFBERkWvftLQ0xcTEyN/fX+vWrdPnn3+uH3/80SG4SdLy5cu1e/duLV++XHPnztWcOXM0Z86cPNf5l19+kaenp+644w57W+3atbV+/XqdPHlSGzZs0Llz51S5cmX98ssv2rhxo5566qk8l9eoUSP9/PPPec4HANwcJZxdAADg1mQYhhISErR48WINHDjQ3u7l5aV3333Xfjjghx9+qKysLL377ruyWCySpPfee0+lSpXSihUr1KZNG40ePVpDhgzRoEGD7Mtp2LBhrs+7f/9+RUZGqmnTprJYLKpQoUKeNX788cc6f/683n//fXl5eUmSpk6dqg4dOmjcuHEKDg6WJPn7+2vq1KlydXVV1apV1b59eyUkJKhXr165Lnffvn0KDg52GBgjJiZGjzzyiBo2bCgPDw/NnTtXXl5e6tu3r+bMmaPp06drypQpCggI0KxZs1S9enX7Y8PCwnTgwAFlZWWZNtgGAKDgCFcAgJvqu+++k7e3ty5cuKCsrCz961//0siRI+3za9as6XCe1W+//aZdu3bJx8fHYTnnz5/X7t27deTIER06dEitW7fO1/M/+uijuueee1SlShW1bdtW9913n9q0aZNr3+3bt6t27dr2YCVJTZo0UVZWlv788097uKpevbpcXV3tfUJDQ/XHH3/kWcO5c+fk7u6eo33kyJEOr8WoUaMUHR2tkiVLavTo0frjjz/03XffqUePHtqwYYO9n4eHh7KyspSeni4PD498vQ4AAPMRrgAAN9Xdd9+t6dOny83NTWFhYSpRwvFP0eVBRpLOnDmj+vXr5xg9T5ICAwMLvKemXr162rNnjxYuXKgff/xRXbp0UXR0tObPn1/wlfl/JUuWdLhvsViuOnpfQECATp48edVl7tixQx9++KE2bdqk2bNnq3nz5goMDFSXLl302GOP6fTp0/bAeeLECXl5eRGsAMDJCFcAgJvKy8srz/OhclOvXj3NmzdPQUFB8vX1zbVPRESEEhISdPfdd+drmb6+vuratau6du2qzp07q23btjpx4oRKly7t0O+OO+7QnDlzlJaWZg99q1atkouLi32wjcKoW7eukpKSdPLkSfn7++eYbxiG+vTpo4kTJ8rb21uZmZn2ATKyf2ZmZtr7b9myRXXr1i10PQAAc3BgNgCgSPv3v/+tgIAAdezYUT///LP27NmjFStW6KmnntLff/8tyXY43RtvvKHJkydr586d2rhxo6ZMmZLr8iZOnKhPPvlEO3bs0F9//aXPP/9cISEhKlWqVK7P7e7urp49e2rLli1avny5Bg4cqP/85z/2QwILo27dugoICNCqVatynf/uu+8qMDDQPppgkyZNtGzZMq1Zs0ZvvvmmqlWr5lDvzz//nOehjQCAm4c9VwCAIs3T01M//fSTnn/+eT344IM6ffq0ypYtq9atW9v3ZPXs2VPnz5/Xm2++qWeeeUYBAQHq3Llzrsvz8fHR+PHjtXPnTrm6uqphw4b64Ycfcj280NPTU4sXL9agQYPUsGFDeXp66qGHHtLEiROva51cXV0VGxurjz76SPfdd5/DvOTkZI0ZM0arV6+2tzVq1EhDhgxR+/btFRQUpLlz59rnHTx4UKtXr9aHH354XTUBAK4fFxEGAMAJkpKSVL16dW3cuPGqIxZey/PPP6+TJ09q1qxZJlYHACgMDgsEAMAJQkJC9N///lf79++/ruUEBQXp1VdfNakqAMD1YM8VAAAAAJiAPVcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJjg/wCuEeLn1HohKQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4412100456621004 9.328891778955349 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcular la media y la desviación estándar de las muestras\n",
    "mu, std = np.mean(muestras), np.std(muestras)\n",
    "\n",
    "# Generar la distribución gaussiana\n",
    "gaussian = norm(loc=mu, scale=std)\n",
    "\n",
    "# Crear un array de valores x para la gráfica\n",
    "x = np.linspace(min(muestras), max(muestras), 100)\n",
    "\n",
    "# Crear la gráfica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(muestras, bins=20, density=True, alpha=0.6, color='g')\n",
    "plt.plot(x, gaussian.pdf(x), 'r', linewidth=2)\n",
    "plt.title('Distribución de las predicciones y la gaussiana')\n",
    "plt.xlabel('Precisión (%)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución muestral de la precisión con 300 muestras')\n",
    "plt.show()\n",
    "print(mu, std, np.median(muestras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 1s 5ms/step - loss: 0.6763 - accuracy: 0.5840 - val_loss: 0.6568 - val_accuracy: 0.6248\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6801 - val_loss: 0.6388 - val_accuracy: 0.6281\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7102 - val_loss: 0.6336 - val_accuracy: 0.6382\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7275 - val_loss: 0.6375 - val_accuracy: 0.6231\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7499 - val_loss: 0.6443 - val_accuracy: 0.6415\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7610 - val_loss: 0.6521 - val_accuracy: 0.6298\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7772 - val_loss: 0.6729 - val_accuracy: 0.6298\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7912 - val_loss: 0.6851 - val_accuracy: 0.6265\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8029 - val_loss: 0.7017 - val_accuracy: 0.6181\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8130 - val_loss: 0.7179 - val_accuracy: 0.6214\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir la capa de entrada y la primera capa oculta\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# Añadir la segunda capa oculta\n",
    "# model.add(Dense(units=32, activation='tanh'))\n",
    "\n",
    "# Añadir la capa de salida\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 901us/step\n",
      "[[0.29038915]\n",
      " [0.87870055]\n",
      " [0.54795855]\n",
      " [0.5245315 ]\n",
      " [0.5045618 ]\n",
      " [0.36112508]\n",
      " [0.7144016 ]\n",
      " [0.03337231]\n",
      " [0.3889252 ]\n",
      " [0.9699946 ]\n",
      " [0.5099    ]\n",
      " [0.36921182]\n",
      " [0.7297144 ]\n",
      " [0.63629687]\n",
      " [0.68620294]\n",
      " [0.6169642 ]\n",
      " [0.39685398]\n",
      " [0.5028087 ]\n",
      " [0.10143806]\n",
      " [0.58792716]\n",
      " [0.8212631 ]\n",
      " [0.2250678 ]\n",
      " [0.71199334]\n",
      " [0.15303053]\n",
      " [0.5367422 ]\n",
      " [0.91462004]\n",
      " [0.8508729 ]\n",
      " [0.45524526]\n",
      " [0.48863417]\n",
      " [0.9108071 ]\n",
      " [0.06258722]\n",
      " [0.46039274]\n",
      " [0.7530577 ]\n",
      " [0.02825113]\n",
      " [0.12024859]\n",
      " [0.33825666]\n",
      " [0.376912  ]\n",
      " [0.87311417]\n",
      " [0.48498312]\n",
      " [0.7625294 ]\n",
      " [0.30032316]\n",
      " [0.3838249 ]\n",
      " [0.34591183]\n",
      " [0.19031383]\n",
      " [0.59378695]\n",
      " [0.04645526]\n",
      " [0.9004796 ]\n",
      " [0.7963751 ]\n",
      " [0.88856345]\n",
      " [0.43073097]\n",
      " [0.5097691 ]\n",
      " [0.54992664]\n",
      " [0.79999274]\n",
      " [0.29630464]\n",
      " [0.32808307]\n",
      " [0.94191605]\n",
      " [0.58851147]\n",
      " [0.7145085 ]\n",
      " [0.38261363]\n",
      " [0.34937716]\n",
      " [0.15770598]\n",
      " [0.63163024]\n",
      " [0.8566286 ]\n",
      " [0.3422166 ]\n",
      " [0.37031204]\n",
      " [0.81734854]\n",
      " [0.30386424]\n",
      " [0.63357127]\n",
      " [0.4132766 ]\n",
      " [0.13944252]\n",
      " [0.8993434 ]\n",
      " [0.81993043]\n",
      " [0.928779  ]\n",
      " [0.5589744 ]\n",
      " [0.9031732 ]\n",
      " [0.4333257 ]\n",
      " [0.966263  ]\n",
      " [0.34137532]\n",
      " [0.30210784]\n",
      " [0.4142767 ]\n",
      " [0.5936948 ]\n",
      " [0.57137865]\n",
      " [0.70118403]\n",
      " [0.42444208]\n",
      " [0.60567254]\n",
      " [0.5119559 ]\n",
      " [0.81980395]\n",
      " [0.83958685]\n",
      " [0.48156446]\n",
      " [0.22719264]\n",
      " [0.3180337 ]\n",
      " [0.544477  ]\n",
      " [0.72462285]\n",
      " [0.55316085]\n",
      " [0.1635039 ]\n",
      " [0.73175997]\n",
      " [0.35445455]\n",
      " [0.46950474]\n",
      " [0.42337462]\n",
      " [0.14543462]\n",
      " [0.59770715]\n",
      " [0.71166337]\n",
      " [0.26250485]\n",
      " [0.911916  ]\n",
      " [0.1807689 ]\n",
      " [0.6726172 ]\n",
      " [0.61888987]\n",
      " [0.13794725]\n",
      " [0.78627235]\n",
      " [0.23046765]\n",
      " [0.02265491]\n",
      " [0.5479582 ]\n",
      " [0.80127144]\n",
      " [0.7855825 ]\n",
      " [0.25492296]\n",
      " [0.71927184]\n",
      " [0.51893324]\n",
      " [0.41003   ]\n",
      " [0.07272943]\n",
      " [0.4579004 ]\n",
      " [0.38307533]\n",
      " [0.21325901]\n",
      " [0.21139282]\n",
      " [0.5115301 ]\n",
      " [0.34748977]\n",
      " [0.59968585]\n",
      " [0.15865752]\n",
      " [0.8911516 ]\n",
      " [0.78618896]\n",
      " [0.7437292 ]\n",
      " [0.37124515]\n",
      " [0.46275613]\n",
      " [0.79193443]\n",
      " [0.6783717 ]\n",
      " [0.9281266 ]\n",
      " [0.14272884]\n",
      " [0.43783745]\n",
      " [0.395536  ]\n",
      " [0.10728297]\n",
      " [0.7662    ]\n",
      " [0.8594547 ]\n",
      " [0.15191278]\n",
      " [0.7620269 ]\n",
      " [0.6900981 ]\n",
      " [0.48479295]\n",
      " [0.12014356]\n",
      " [0.57372683]\n",
      " [0.6667479 ]\n",
      " [0.7833844 ]\n",
      " [0.43734258]\n",
      " [0.30903915]\n",
      " [0.7689365 ]\n",
      " [0.8121776 ]\n",
      " [0.63066185]\n",
      " [0.7237454 ]\n",
      " [0.27967614]\n",
      " [0.15185842]\n",
      " [0.08074997]\n",
      " [0.7248197 ]\n",
      " [0.540217  ]\n",
      " [0.753797  ]\n",
      " [0.88325185]\n",
      " [0.7646383 ]\n",
      " [0.75044215]\n",
      " [0.74263114]\n",
      " [0.7799942 ]\n",
      " [0.39662763]\n",
      " [0.58041126]\n",
      " [0.7802573 ]\n",
      " [0.25723547]\n",
      " [0.37327072]\n",
      " [0.1970068 ]\n",
      " [0.63371915]\n",
      " [0.08839175]\n",
      " [0.77939355]\n",
      " [0.33222622]\n",
      " [0.87363756]\n",
      " [0.24638008]\n",
      " [0.32215974]\n",
      " [0.53605175]\n",
      " [0.70324063]\n",
      " [0.09076488]\n",
      " [0.5594987 ]\n",
      " [0.7781689 ]\n",
      " [0.1265626 ]\n",
      " [0.54365224]\n",
      " [0.8328807 ]\n",
      " [0.5181499 ]\n",
      " [0.719526  ]\n",
      " [0.36935872]\n",
      " [0.42929217]\n",
      " [0.26915836]\n",
      " [0.825287  ]\n",
      " [0.69914377]\n",
      " [0.7896503 ]\n",
      " [0.5929218 ]\n",
      " [0.36789346]\n",
      " [0.06967416]\n",
      " [0.36219272]\n",
      " [0.17540462]\n",
      " [0.17958838]\n",
      " [0.7240114 ]\n",
      " [0.9187424 ]\n",
      " [0.95611   ]\n",
      " [0.3546916 ]\n",
      " [0.4068692 ]\n",
      " [0.55423945]\n",
      " [0.22259194]\n",
      " [0.5888203 ]\n",
      " [0.6567697 ]\n",
      " [0.28763306]\n",
      " [0.95072645]\n",
      " [0.35191575]\n",
      " [0.8888269 ]\n",
      " [0.36484694]\n",
      " [0.46264714]\n",
      " [0.81760204]\n",
      " [0.43403143]\n",
      " [0.67997444]\n",
      " [0.2595402 ]\n",
      " [0.41683134]\n",
      " [0.20436466]\n",
      " [0.72739965]\n",
      " [0.18859385]\n",
      " [0.71990114]\n",
      " [0.86876106]\n",
      " [0.30463603]\n",
      " [0.227046  ]\n",
      " [0.5631134 ]\n",
      " [0.3948604 ]\n",
      " [0.7115511 ]\n",
      " [0.4429624 ]\n",
      " [0.78006524]\n",
      " [0.46917623]\n",
      " [0.28328633]\n",
      " [0.40698248]\n",
      " [0.44480148]\n",
      " [0.69472414]\n",
      " [0.98287195]\n",
      " [0.60712326]\n",
      " [0.53186256]\n",
      " [0.61492294]\n",
      " [0.27218676]\n",
      " [0.4952043 ]\n",
      " [0.49185893]\n",
      " [0.8858242 ]\n",
      " [0.7583877 ]\n",
      " [0.6371346 ]\n",
      " [0.52427644]\n",
      " [0.587449  ]\n",
      " [0.7172712 ]\n",
      " [0.46534568]\n",
      " [0.6664219 ]\n",
      " [0.8735328 ]\n",
      " [0.47444794]\n",
      " [0.24893942]\n",
      " [0.3188743 ]\n",
      " [0.7850809 ]\n",
      " [0.7103164 ]\n",
      " [0.8947788 ]\n",
      " [0.34500447]\n",
      " [0.41217408]\n",
      " [0.03610977]\n",
      " [0.8616765 ]\n",
      " [0.7763007 ]\n",
      " [0.81472254]\n",
      " [0.60176337]\n",
      " [0.31067005]\n",
      " [0.4728744 ]\n",
      " [0.6303721 ]\n",
      " [0.32249433]\n",
      " [0.2265841 ]\n",
      " [0.5442401 ]\n",
      " [0.6749637 ]\n",
      " [0.74645984]\n",
      " [0.7228061 ]\n",
      " [0.32280338]\n",
      " [0.22120081]\n",
      " [0.160415  ]\n",
      " [0.07954774]\n",
      " [0.94515926]\n",
      " [0.38452446]\n",
      " [0.76808375]\n",
      " [0.46942875]\n",
      " [0.4540702 ]\n",
      " [0.51066077]\n",
      " [0.54680383]\n",
      " [0.6519109 ]\n",
      " [0.6609704 ]\n",
      " [0.43118694]\n",
      " [0.38993233]\n",
      " [0.5373369 ]\n",
      " [0.50685686]\n",
      " [0.89154416]\n",
      " [0.35760728]\n",
      " [0.6809383 ]\n",
      " [0.73373264]\n",
      " [0.7661781 ]\n",
      " [0.18737671]\n",
      " [0.61405945]\n",
      " [0.7657272 ]\n",
      " [0.23903045]\n",
      " [0.8332942 ]\n",
      " [0.2880266 ]\n",
      " [0.10040917]\n",
      " [0.4500405 ]\n",
      " [0.361697  ]\n",
      " [0.14447887]\n",
      " [0.4123221 ]\n",
      " [0.11389048]\n",
      " [0.17966858]\n",
      " [0.22434062]\n",
      " [0.40100402]\n",
      " [0.4827723 ]\n",
      " [0.76297534]\n",
      " [0.15690471]\n",
      " [0.26064974]\n",
      " [0.7133887 ]\n",
      " [0.29241914]\n",
      " [0.36287293]\n",
      " [0.22461997]\n",
      " [0.8235744 ]\n",
      " [0.65311295]\n",
      " [0.13279466]\n",
      " [0.8085371 ]\n",
      " [0.7916    ]\n",
      " [0.11964697]\n",
      " [0.24455875]\n",
      " [0.92946637]\n",
      " [0.34378377]\n",
      " [0.9026996 ]\n",
      " [0.86061645]\n",
      " [0.5864899 ]\n",
      " [0.76746655]\n",
      " [0.10777178]\n",
      " [0.45232975]\n",
      " [0.09268378]\n",
      " [0.3069989 ]\n",
      " [0.1674706 ]\n",
      " [0.92813045]\n",
      " [0.8116808 ]\n",
      " [0.4870881 ]\n",
      " [0.7386964 ]\n",
      " [0.08794155]\n",
      " [0.0776751 ]\n",
      " [0.779647  ]\n",
      " [0.7890339 ]\n",
      " [0.8349532 ]\n",
      " [0.82109755]\n",
      " [0.89231205]\n",
      " [0.0500595 ]\n",
      " [0.68981564]\n",
      " [0.4117504 ]\n",
      " [0.89731723]\n",
      " [0.16425465]\n",
      " [0.07273399]\n",
      " [0.46999267]\n",
      " [0.06383134]\n",
      " [0.5401844 ]\n",
      " [0.94546854]\n",
      " [0.555591  ]\n",
      " [0.7146889 ]\n",
      " [0.5929292 ]\n",
      " [0.59863967]\n",
      " [0.68422675]\n",
      " [0.02487819]\n",
      " [0.5514036 ]\n",
      " [0.49107414]\n",
      " [0.7730563 ]\n",
      " [0.8495944 ]\n",
      " [0.6905358 ]\n",
      " [0.17637138]\n",
      " [0.65369844]\n",
      " [0.31929725]\n",
      " [0.06723527]\n",
      " [0.6071288 ]\n",
      " [0.380679  ]\n",
      " [0.7143896 ]\n",
      " [0.451933  ]\n",
      " [0.22104315]\n",
      " [0.658188  ]\n",
      " [0.76161915]\n",
      " [0.21936314]\n",
      " [0.06367086]\n",
      " [0.01831302]\n",
      " [0.16710597]\n",
      " [0.47478467]\n",
      " [0.29993814]\n",
      " [0.7391697 ]\n",
      " [0.73751783]\n",
      " [0.73413163]\n",
      " [0.8323652 ]\n",
      " [0.8184632 ]\n",
      " [0.22876008]\n",
      " [0.5155241 ]\n",
      " [0.48553237]\n",
      " [0.9206982 ]\n",
      " [0.7807578 ]\n",
      " [0.68912923]\n",
      " [0.48279974]\n",
      " [0.09648792]\n",
      " [0.48598906]\n",
      " [0.80639464]\n",
      " [0.44945213]\n",
      " [0.42341015]\n",
      " [0.7391161 ]\n",
      " [0.6343579 ]\n",
      " [0.66977566]\n",
      " [0.8146194 ]\n",
      " [0.50674355]\n",
      " [0.8002315 ]\n",
      " [0.6532218 ]\n",
      " [0.25499347]\n",
      " [0.56951684]\n",
      " [0.4624696 ]\n",
      " [0.18498398]\n",
      " [0.5606897 ]\n",
      " [0.13435687]\n",
      " [0.49511632]\n",
      " [0.6756084 ]\n",
      " [0.7909388 ]\n",
      " [0.5135623 ]\n",
      " [0.57497317]\n",
      " [0.87424475]\n",
      " [0.63754255]\n",
      " [0.8279986 ]\n",
      " [0.7707347 ]\n",
      " [0.70386505]\n",
      " [0.88471293]\n",
      " [0.17414191]\n",
      " [0.49536327]\n",
      " [0.17252599]\n",
      " [0.27936012]\n",
      " [0.60983235]\n",
      " [0.56932676]\n",
      " [0.65877473]\n",
      " [0.6040165 ]\n",
      " [0.8445939 ]\n",
      " [0.1248036 ]\n",
      " [0.30407208]\n",
      " [0.87962896]\n",
      " [0.39058995]\n",
      " [0.52238023]\n",
      " [0.5713639 ]\n",
      " [0.7182911 ]\n",
      " [0.08247868]\n",
      " [0.19403747]\n",
      " [0.389739  ]\n",
      " [0.37362084]\n",
      " [0.6763173 ]\n",
      " [0.8974464 ]\n",
      " [0.81938064]\n",
      " [0.8025022 ]\n",
      " [0.26080757]\n",
      " [0.65505373]\n",
      " [0.7765777 ]\n",
      " [0.8306002 ]\n",
      " [0.48977566]\n",
      " [0.51036537]\n",
      " [0.12409914]\n",
      " [0.67252535]\n",
      " [0.16159149]\n",
      " [0.8508825 ]\n",
      " [0.56391144]\n",
      " [0.21759725]\n",
      " [0.90003663]\n",
      " [0.81732446]\n",
      " [0.9287658 ]\n",
      " [0.23870021]\n",
      " [0.82479376]\n",
      " [0.99147433]\n",
      " [0.2898865 ]\n",
      " [0.10766983]\n",
      " [0.6427981 ]\n",
      " [0.2143432 ]\n",
      " [0.24021576]\n",
      " [0.79200464]\n",
      " [0.7412877 ]\n",
      " [0.66556436]\n",
      " [0.3784839 ]\n",
      " [0.7012631 ]\n",
      " [0.1941483 ]\n",
      " [0.6926489 ]\n",
      " [0.13930608]\n",
      " [0.34602606]\n",
      " [0.43135402]\n",
      " [0.67175   ]\n",
      " [0.85114956]\n",
      " [0.0436648 ]\n",
      " [0.2081627 ]\n",
      " [0.25413072]\n",
      " [0.9711218 ]\n",
      " [0.8668433 ]\n",
      " [0.5773359 ]\n",
      " [0.2646596 ]\n",
      " [0.2311122 ]\n",
      " [0.62655866]\n",
      " [0.59283   ]\n",
      " [0.4683576 ]\n",
      " [0.7657165 ]\n",
      " [0.7970574 ]\n",
      " [0.10950694]\n",
      " [0.55307436]\n",
      " [0.9365593 ]\n",
      " [0.5914766 ]\n",
      " [0.7024065 ]\n",
      " [0.76141834]\n",
      " [0.4452815 ]\n",
      " [0.36408764]\n",
      " [0.7600084 ]\n",
      " [0.23869622]\n",
      " [0.37162268]\n",
      " [0.8505188 ]\n",
      " [0.23615585]\n",
      " [0.3888902 ]\n",
      " [0.5891161 ]\n",
      " [0.51792294]\n",
      " [0.19605382]\n",
      " [0.2006269 ]\n",
      " [0.22502458]\n",
      " [0.2366951 ]\n",
      " [0.369282  ]\n",
      " [0.02837017]\n",
      " [0.6436601 ]\n",
      " [0.9007374 ]\n",
      " [0.20255883]\n",
      " [0.39048022]\n",
      " [0.50355446]\n",
      " [0.78147024]\n",
      " [0.4250272 ]\n",
      " [0.3223028 ]\n",
      " [0.7496787 ]\n",
      " [0.3523106 ]\n",
      " [0.06189683]\n",
      " [0.7439459 ]\n",
      " [0.14581187]\n",
      " [0.4559738 ]\n",
      " [0.8758111 ]\n",
      " [0.9077667 ]\n",
      " [0.80426776]\n",
      " [0.13479276]\n",
      " [0.4844548 ]\n",
      " [0.0875758 ]\n",
      " [0.49681607]\n",
      " [0.52275497]\n",
      " [0.8403715 ]\n",
      " [0.33885947]\n",
      " [0.17589225]\n",
      " [0.21504538]\n",
      " [0.5066613 ]\n",
      " [0.20687596]\n",
      " [0.4010023 ]\n",
      " [0.04717069]\n",
      " [0.48648095]\n",
      " [0.74748117]\n",
      " [0.7441924 ]\n",
      " [0.24992108]\n",
      " [0.22211525]\n",
      " [0.8951802 ]\n",
      " [0.74545985]\n",
      " [0.10262665]\n",
      " [0.49460405]\n",
      " [0.70661336]\n",
      " [0.32949305]\n",
      " [0.6803564 ]\n",
      " [0.93683964]\n",
      " [0.7712195 ]\n",
      " [0.12966642]\n",
      " [0.6719627 ]\n",
      " [0.47776672]\n",
      " [0.94204926]\n",
      " [0.97581   ]\n",
      " [0.32851595]\n",
      " [0.8885245 ]\n",
      " [0.44886002]\n",
      " [0.59720546]\n",
      " [0.07098941]\n",
      " [0.39067864]\n",
      " [0.25585234]\n",
      " [0.98324203]\n",
      " [0.08835097]\n",
      " [0.1677489 ]\n",
      " [0.754604  ]\n",
      " [0.9742989 ]\n",
      " [0.7594027 ]\n",
      " [0.303429  ]\n",
      " [0.10319124]\n",
      " [0.5762346 ]\n",
      " [0.5655729 ]\n",
      " [0.8369239 ]\n",
      " [0.7722106 ]\n",
      " [0.35651866]\n",
      " [0.0578959 ]\n",
      " [0.34896627]\n",
      " [0.2623179 ]\n",
      " [0.9746833 ]\n",
      " [0.8228528 ]\n",
      " [0.4421009 ]]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos la predicción\n",
    "prediccion_test = model.predict(X_test)\n",
    "predicciones = [1 if p > 0.5 else 0 for p in prediccion_test]\n",
    "print(prediccion_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 0, -1, 1, 1, -1, -1, 1, 0, -1, -1, 0, 0, -1, -1, 1, -1, -1, -1, -1, -1, 0, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, 0, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, 1, 0, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 0, -1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, 1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, 0, 0, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, 0, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, 0, 1, -1, 0, -1, 1, -1, 1, 1, -1, -1, 0, -1, 0, -1, 0, 1, 1, -1, -1, 0, 0, -1, -1, 1, 1, 1, 0, -1, -1, 1, 0, 0, -1, 0, -1, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 0, -1, 0, -1, -1, -1, -1, -1, 1, 0, -1, 1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, 0, -1, 0, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, 1, 0, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, 1, 1, 1, 0, -1, 0, -1, -1, 1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 1, -1, 0, -1, -1, 1, 1, -1, 1, -1, -1, 0, -1, -1, 1, 0, 0, -1, 1, -1, -1, 0, -1, -1, 1, -1, -1, 0, -1, -1, 1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Filtrar valores mayores que 0.7 o menores que 0.3\n",
    "valores_filtrados = [1 if p > 0.80 else (0 if p < 0.20 else -1) for p in prediccion_test]\n",
    "\n",
    "print(valores_filtrados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del test: 59.7%\n"
     ]
    }
   ],
   "source": [
    "# Veamos cuántos partidos ha acertado para el test\n",
    "aciertos = 0\n",
    "for i in range(len(predicciones)):\n",
    "    if predicciones[i] == y_test[i]:\n",
    "        aciertos += 1\n",
    "print(f\"Precisión del test: {np.round(aciertos / len(predicciones)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del test: 65.95% para el 30.94% de partidos\n",
      "[1, 7, 9, 18, 20, 23, 25, 26, 29, 30, 33, 34, 37, 43, 45, 46, 48, 55, 60, 62, 65, 69, 70, 71, 72, 74, 76, 86, 87, 94, 99, 103, 104, 107, 110, 112, 118, 126, 127, 134, 135, 138, 140, 141, 145, 152, 156, 157, 161, 171, 173, 176, 181, 184, 186, 192, 197, 199, 200, 202, 203, 211, 213, 216, 223, 225, 238, 245, 253, 259, 262, 263, 265, 278, 279, 280, 293, 298, 302, 304, 307, 309, 310, 315, 321, 323, 324, 326, 328, 330, 331, 334, 336, 338, 339, 340, 343, 344, 347, 348, 349, 350, 353, 354, 355, 357, 359, 365, 369, 371, 374, 383, 384, 385, 391, 392, 396, 400, 402, 408, 410, 415, 417, 423, 425, 428, 429, 431, 437, 438, 440, 445, 446, 450, 451, 452, 456, 459, 461, 462, 465, 466, 467, 469, 470, 472, 481, 483, 487, 488, 491, 492, 501, 503, 512, 517, 522, 524, 533, 535, 537, 538, 539, 540, 542, 545, 547, 552, 558, 560, 565, 567, 570, 571, 573, 576, 579, 580, 581, 583, 586, 589, 592, 595, 596]\n"
     ]
    }
   ],
   "source": [
    "# Veamos cuántos partidos ha acertado para el test\n",
    "aciertos = 0\n",
    "n = 0\n",
    "indices = list()\n",
    "for i in range(len(valores_filtrados)):\n",
    "    if valores_filtrados[i] != -1:\n",
    "        n += 1\n",
    "        indices.append(i)\n",
    "        if valores_filtrados[i] == y_test[i]:\n",
    "            aciertos += 1\n",
    "print(f\"Precisión del test: {np.round(aciertos / n*100, 2)}% para el {np.round(n/len(y_test)*100, 2)}% de partidos\")\n",
    "print(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
